# è¯¾æ—¶äºŒ è½»æ¾åˆ†é’Ÿç©è½¬ä¹¦ç”ŸÂ·æµ¦è¯­å¤§æ¨¡å‹è¶£å‘³ Demo

![Helloword](image.png)

[é£ä¹¦åœ°å€](https://aicarrier.feishu.cn/wiki/Vv4swUFMni5DiMkcasUczUp9nid#LSBkd2cTHorhsAx5jZAcO0B3nqe)






## 1. æäº¤çš„ä½œä¸šç»“æœ

[ä½œä¸šè¦æ±‚](https://github.com/InternLM/Tutorial/blob/camp2/helloworld/homework.md)

### 1.1 ä½œä¸š1
- ä½¿ç”¨ InternLM2-Chat-1.8B æ¨¡å‹ç”Ÿæˆ 300 å­—çš„å°æ•…äº‹ï¼ˆæˆªå›¾ï¼‰

  ![å¯“è¨€æ•…äº‹](image-11.png)

### 1.2 ä½œä¸š2
- ç†Ÿæ‚‰ huggingface ä¸‹è½½åŠŸèƒ½ï¼Œä½¿ç”¨ huggingface_hub python åŒ…ï¼Œä¸‹è½½ InternLM2-Chat-7B çš„ config.json æ–‡ä»¶åˆ°æœ¬åœ°ï¼ˆæˆªå›¾ä¸‹è½½è¿‡ç¨‹ï¼‰

  ![ä¸‹è½½è¿‡ç¨‹](image-12.png)

### 1.3 ä½œä¸š3

- å®Œæˆ Lagent å·¥å…·è°ƒç”¨ æ•°æ®åˆ†æ Demo éƒ¨ç½²ï¼ˆæˆªå›¾ï¼‰

  - è§‚å¯Ÿæ¨¡å‹åŠ è½½è¿›åº¦

    ![alt text](image-28.png)
    
  - å‹¾é€‰æ•°æ®åˆ†æ

    ![alt text](image-29.png)

### 1.4 ä½œä¸š4

- å®Œæˆ æµ¦è¯­Â·çµç¬”2 çš„ å›¾æ–‡åˆ›ä½œ åŠ è§†è§‰é—®ç­” éƒ¨ç½²ï¼ˆæˆªå›¾ï¼‰

### 1.5 ä¸šç¬”è®°

#### 1.5.1 æ¨¡å‹ç”Ÿæˆå°æ•…äº‹

#### 1.5.2 huggingfaceä¸‹è½½æ¨¡å‹

- [æ¨¡å‹åœ°å€](https://huggingface.co/internlm/internlm2-chat-1_8b)

- [huggingface hub pythonæ–‡æ¡£](https://huggingface.co/docs/huggingface_hub/quick-start)

è¿›å…¥demoç¯å¢ƒï¼ˆcondaï¼‰ï¼Œè¾“å…¥pythonè¿›å…¥pythonå‘½ä»¤ç¼–å†™å¦‚ä¸‹ä»£ç è¿›è¡Œæ¨¡å‹configä¸‹è½½

``` python linenums="1"
from huggingface_hub import hf_hub_download
hf_hub_download(repo_id="internlm/internlm2-chat-1_8b", filename="config.json")
```

![ä¸‹è½½è¿‡ç¨‹](image-12.png)

#### 1.5.3 Lagent æ™ºèƒ½ä½“

#### 1.5.4 çµç¬”2éƒ¨ç½²

- å›¾æ–‡åˆ›ä½œ

- è§†è§‰é—®ç­”


## 2. è§†é¢‘ç¬”è®°

[è§†é¢‘é“¾æ¥](https://www.bilibili.com/video/BV1AH4y1H78d/)

### å®æˆ˜ä»»åŠ¡

- åˆ—è¡¨
  ![alt text](image-31.png)


## 3. æ–‡æ¡£å¤ç°ç¬”è®°

[æ–‡æ¡£é“¾æ¥](https://github.com/InternLM/Tutorial/blob/camp2/helloworld/hello_world.md)

### 3.1 éƒ¨ç½²InternLM2-Chat-1.8B æ¨¡å‹è¿›è¡Œæ™ºèƒ½å¯¹è¯

#### 3.1.1 é…ç½®åŸºç¡€ç¯å¢ƒ

- åˆ›å»ºå¼€å‘æœº

  è¿›å…¥[ç®—åŠ›å¹³å°](https://studio.intern-ai.org.cn/)ç‚¹å‡»åˆ›å»ºå¼€å‘æœºï¼Œé€‰æ‹©ç®—åŠ›â€”â€”>å¼€å‘æœºå‘½åâ€”â€”>é€‰æ‹©é•œåƒï¼ˆcuda11.7-condaï¼‰â€”â€”>è®¾ç½®ç®—åŠ›ç”¨æ—¶ã€‚

  ![alt text](image-2.png)


- é…ç½®å¼€å‘æœºå¼€å‘ç¯å¢ƒ
  
  è¿›å…¥å¼€å‘æœºç»ˆç«¯ï¼Œè¾“å…¥å¦‚ä¸‹å‘½ä»¤å®‰è£…condaå¼€å‘ç¯å¢ƒï¼ˆå®æµ‹è¿è¡Œ12åˆ†é’Ÿå·¦å³ï¼‰
  
  ``` bash
  studio-conda -o internlm-base -t demo
  # ä¸ studio-conda ç­‰æ•ˆçš„é…ç½®æ–¹æ¡ˆ
  # conda create -n demo python==3.10 -y
  # conda activate demo
  # conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia
  ```
  ![å¼€å‘æœºç»ˆç«¯](image-1.png)

  - conda create -n demo python==3.10 -y: è¿™ä¸ªå‘½ä»¤ä½¿ç”¨condaåŒ…ç®¡ç†å™¨åˆ›å»ºä¸€ä¸ªåä¸º"demo"çš„ç¯å¢ƒï¼Œå¹¶æŒ‡å®šä½¿ç”¨Python 3.10ç‰ˆæœ¬ã€‚-yé€‰é¡¹è¡¨ç¤ºåœ¨åˆ›å»ºç¯å¢ƒæ—¶è‡ªåŠ¨ç¡®è®¤æ‰€æœ‰æç¤ºï¼Œæ— éœ€æ‰‹åŠ¨ç¡®è®¤ã€‚

  - conda activate demo: è¿™ä¸ªå‘½ä»¤ç”¨äºæ¿€æ´»åä¸º"demo"çš„ç¯å¢ƒã€‚æ¿€æ´»ç¯å¢ƒåï¼Œæ‰€æœ‰åç»­çš„å‘½ä»¤å’Œæ“ä½œéƒ½å°†åœ¨è¯¥ç¯å¢ƒä¸­è¿›è¡Œã€‚

  - conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia: è¿™ä¸ªå‘½ä»¤ä½¿ç”¨condaå®‰è£…ç‰¹å®šç‰ˆæœ¬çš„PyTorchåŠå…¶ç›¸å…³åº“ã€‚pytorch==2.0.1è¡¨ç¤ºå®‰è£…PyTorch 2.0.1ç‰ˆæœ¬ï¼Œtorchvision==0.15.2è¡¨ç¤ºå®‰è£…torchvisionåº“çš„0.15.2ç‰ˆæœ¬ï¼Œtorchaudio==2.0.2è¡¨ç¤ºå®‰è£…torchaudioåº“çš„2.0.2ç‰ˆæœ¬ã€‚pytorch-cuda=11.7è¡¨ç¤ºå®‰è£…æ”¯æŒCUDA 11.7çš„PyTorchç‰ˆæœ¬ã€‚-c pytorch -c nvidiaæŒ‡å®šäº†ä»pytorchå’Œnvidiaè¿™ä¸¤ä¸ªæ¸ é“è¿›è¡Œå®‰è£…ã€‚

  ![condaç¯å¢ƒå®‰è£…ç»“æœ1](image-3.png)
  
  ![condaç¯å¢ƒå®‰è£…ç»“æœ2](image-4.png)

  æŸ¥çœ‹condaç¯å¢ƒlist

  ![alt text](image-5.png)

  è¿›å…¥å¼€å‘ç¯å¢ƒ
  ``` bash
    conda activate demo
  ```

  

  è¿›è¡Œç¯å¢ƒä¾èµ–åŒ…å®‰è£…

  ``` bash
   pip install huggingface-hub==0.17.3
   pip install transformers==4.34 
   pip install psutil==5.9.8
   pip install accelerate==0.24.1
   pip install streamlit==1.32.2 
   pip install matplotlib==3.8.3 
   pip install modelscope==1.9.5
   pip install sentencepiece==0.1.99
  ```

    - huggingface-hub: æä¾›äº†ä¸Hugging Faceæ¨¡å‹å’Œæ•°æ®é›†åº“çš„äº¤äº’åŠŸèƒ½ã€‚

    - transformers: æä¾›äº†ç”¨äºè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡çš„é¢„è®­ç»ƒæ¨¡å‹å’Œç›¸å…³å·¥å…·ã€‚

    - psutil: æä¾›äº†ä¸€ä¸ªè·¨å¹³å°çš„åº“ï¼Œç”¨äºè·å–ç³»ç»Ÿä¿¡æ¯å’Œè¿›ç¨‹ç®¡ç†ã€‚

    - accelerate: æä¾›äº†ç”¨äºåŠ é€Ÿæ·±åº¦å­¦ä¹ è®­ç»ƒçš„å·¥å…·å’ŒAPIã€‚

    - streamlit: æä¾›äº†ä¸€ä¸ªç”¨äºæ„å»ºäº¤äº’å¼Webåº”ç”¨ç¨‹åºçš„Pythonåº“ã€‚

    - matplotlib: æä¾›äº†ä¸€ä¸ªç”¨äºç»˜åˆ¶å›¾è¡¨å’Œå¯è§†åŒ–æ•°æ®çš„Pythonåº“ã€‚

    - modelscope: æä¾›äº†ä¸€ä¸ªç”¨äºåˆ†æå’Œæ¯”è¾ƒæœºå™¨å­¦ä¹ æ¨¡å‹çš„Pythonåº“ã€‚

    - sentencepiece: æä¾›äº†ä¸€ä¸ªç”¨äºåˆ†è¯å’Œç”Ÿæˆå­è¯å•å…ƒçš„å·¥å…·å’Œåº“ã€‚

#### 3.1.2 ä¸‹è½½å¤§æ¨¡å‹

  è¿›å…¥jupyterç»ˆç«¯ï¼Œè¿›å…¥demoç¯å¢ƒï¼ˆcondaï¼‰ï¼Œcdåˆ°å½“å‰jupyterè·¯å¾„ä¸‹ã€‚

``` bash
  cd /root
  conda activate demo
```
![ä¸‹è½½å¤§æ¨¡å‹ç¯å¢ƒ](image-6.png)

  åˆ›å»ºæ–‡ä»¶å¤¹&pythonæ–‡ä»¶

  ``` bash
   mkdir demo
   cd demo
   tourch cli_demo.py
   tourch download_mini.py
  ```

  ![åˆ›å»ºæ–‡ä»¶å¤¹&æ–‡ä»¶](image-7.png)

  ç¼–å†™è„šæœ¬â€”â€”download_mini.py

  ``` python linenums="1"
  import os  # å¯¼å…¥osæ¨¡å—ï¼Œç”¨äºæ“ä½œç³»ç»Ÿç›¸å…³çš„æ“ä½œ
  from modelscope.hub.snapshot_download import snapshot_download  # ä»modelscope.hubæ¨¡å—å¯¼å…¥snapshot_downloadå‡½æ•°ï¼Œç”¨äºä¸‹è½½æ¨¡å‹

  # åˆ›å»ºä¿å­˜æ¨¡å‹ç›®å½•
  os.system("mkdir /root/models")  # ä½¿ç”¨os.systemæ‰§è¡Œå‘½ä»¤è¡Œå‘½ä»¤ï¼Œåˆ›å»ºä¸€ä¸ªåä¸ºmodelsçš„ç›®å½•åœ¨/rootè·¯å¾„ä¸‹

  # save_diræ˜¯æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„ç›®å½•
  save_dir="/root/models"  # å®šä¹‰å˜é‡save_dirï¼Œå…¶å€¼ä¸ºæ¨¡å‹ä¿å­˜çš„ç›®å½•è·¯å¾„

  # ä½¿ç”¨snapshot_downloadå‡½æ•°ä¸‹è½½æ¨¡å‹ï¼Œå‚æ•°åŒ…æ‹¬æ¨¡å‹çš„åå­—ï¼Œç¼“å­˜ç›®å½•å’Œç‰ˆæœ¬å·
  snapshot_download("Shanghai_AI_Laboratory/internlm2-chat-1_8b", 
                    cache_dir=save_dir, 
                    revision='v1.1.0')
  ```

  æ‰§è¡Œå‘½ä»¤ä¸‹è½½æ¨¡å‹

  ``` bash
    python download_mini.py
  ```
  ![ä¸‹è½½å¤§æ¨¡å‹](image-8.png)

  ![å¤§æ¨¡å‹æ–‡ä»¶](image-9.png)

  #### 3.1.3 åŸºäºå¤§æ¨¡å‹å¯¹è¯

    ç¼–å†™cli_demo.pyè„šæœ¬
  
  ```python  linenums="1"
        import torch  # å¯¼å…¥torchåº“ï¼Œç”¨äºè¿›è¡Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ“ä½œ
        from transformers import AutoTokenizer, AutoModelForCausalLM  # ä»transformersåº“ä¸­å¯¼å…¥AutoTokenizerå’ŒAutoModelForCausalLMï¼Œç”¨äºå¤„ç†è‡ªç„¶è¯­è¨€å’ŒåŠ è½½æ¨¡å‹

        model_name_or_path = "/root/models/Shanghai_AI_Laboratory/internlm2-chat-1_8b"  # æ¨¡å‹çš„åç§°æˆ–è·¯å¾„

        tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, device_map='cuda:0')  # åŠ è½½é¢„è®­ç»ƒçš„tokenizer
        model = AutoModelForCausalLM.from_pretrained(model_name_or_path, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map='cuda:0')  # åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹
        model = model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼

        system_prompt = """You are an AI assistant whose name is InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­).
        - InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­) is a conversational language model that is developed by Shanghai AI Laboratory (ä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤). It is designed to be helpful, honest, and harmless.
        - InternLM (ä¹¦ç”ŸÂ·æµ¦è¯­) can understand and communicate fluently in the language chosen by the user such as English and ä¸­æ–‡.
        """  # ç³»ç»Ÿæç¤ºä¿¡æ¯

        messages = [(system_prompt, '')]  # åˆå§‹åŒ–æ¶ˆæ¯åˆ—è¡¨

        print("=============Welcome to InternLM chatbot, type 'exit' to exit.=============")  # æ‰“å°æ¬¢è¿ä¿¡æ¯

        while True:  # å¾ªç¯æ¥æ”¶ç”¨æˆ·è¾“å…¥
          input_text = input("\nUser  >>> ")  # è·å–ç”¨æˆ·è¾“å…¥
          input_text = input_text.replace(' ', '')  # å»é™¤ç”¨æˆ·è¾“å…¥çš„ç©ºæ ¼
          if input_text == "exit":  # å¦‚æœç”¨æˆ·è¾“å…¥'exit'ï¼Œåˆ™é€€å‡ºå¾ªç¯
            break

          length = 0
          for response, _ in model.stream_chat(tokenizer, input_text, messages):  # ä½¿ç”¨æ¨¡å‹è¿›è¡ŒèŠå¤©
            if response is not None:  # å¦‚æœå“åº”ä¸ä¸ºç©º
              print(response[length:], flush=True, end="")  # æ‰“å°å“åº”
              length = len(response)  # æ›´æ–°å“åº”é•¿åº¦
  ```

  ![è¿è¡Œæˆªå›¾](image-10.png)

  è¾“å…¥æç¤ºè¯ï¼šåˆ›ä½œä¸€ä¸ª300å­—çš„å¯“è¨€æ•…äº‹ï¼Œè¦æ±‚æœ‰è¶£
  ![å¯“è¨€æ•…äº‹](image-11.png)

### 3.2 éƒ¨ç½²å…«æˆ’-Chat-1.8Bæ¨¡å‹

#### 3.2.1 è¿›å…¥ç¯å¢ƒ&ä¸‹è½½æºç 

``` bash linenums="1"
conda activate demo
cd /root/
git clone https://gitee.com/InternLM/Tutorial -b camp2
# git clone https://github.com/InternLM/Tutorial -b camp2
cd /root/Tutorial
```

![æºç ](image-13.png)

#### 3.2.2 è¿è¡ŒChat-å…«æˆ’

- bajie_download.py

``` python linenums="1"
import os
#æ¨¡å‹ä¸‹è½½
from modelscope.hub.snapshot_download import snapshot_download

# åˆ›å»ºä¿å­˜æ¨¡å‹ç›®å½•
os.system("mkdir -p /root/models")

# save_diræ˜¯æ¨¡å‹ä¿å­˜åˆ°æœ¬åœ°çš„ç›®å½•
save_dir="/root/models"

snapshot_download('JimmyMa99/BaJie-Chat-mini', 
                  cache_dir=save_dir)
```

- è¿è¡Œæ¨¡å‹ä¸‹è½½ä»£ç 
``` bash
python /root/Tutorial/helloworld/bajie_download.py
```

![ä¸‹è½½æ¨¡å‹](image-14.png)

- è¿è¡Œå¯åŠ¨streamlitå‰ç«¯é¡µé¢

``` bash
streamlit run /root/Tutorial/helloworld/bajie_chat.py --server.address 127.0.0.1 --server.port 6006
```

![streamlit app](image-15.png)

- æœ¬åœ°ç«¯å£æ˜ å°„

ç‚¹å‡»SSHè¿æ¥ï¼Œæ‰¾å¯»è‡ªå·±çš„ç«¯å£å·ï¼Œå¹¶å¯¹åº”ä¿®æ”¹sshæ˜ å°„å‘½ä»¤çš„ç«¯å£å·

``` bash
# ä»æœ¬åœ°ä½¿ç”¨ ssh è¿æ¥ studio ç«¯å£
# å°†ä¸‹æ–¹ç«¯å£å· 38374 æ›¿æ¢æˆè‡ªå·±çš„ç«¯å£å·
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 38374
```

``` markdown
ssh: è¿™æ˜¯SSHå®¢æˆ·ç«¯å‘½ä»¤ï¼Œç”¨äºå»ºç«‹å®‰å…¨çš„è¿œç¨‹è¿æ¥ã€‚

-CNg: è¿™æ˜¯sshå‘½ä»¤çš„é€‰é¡¹ã€‚-Cé€‰é¡¹å¯ç”¨å‹ç¼©ï¼Œ-Né€‰é¡¹æŒ‡ç¤ºsshä¸è¦æ‰§è¡Œè¿œç¨‹å‘½ä»¤ï¼Œ-gé€‰é¡¹å…è®¸è¿œç¨‹ä¸»æœºé€šè¿‡éš§é“è¿æ¥åˆ°æœ¬åœ°ä¸»æœºã€‚

-L 6006:127.0.0.1:6006: è¿™æ˜¯sshå‘½ä»¤çš„ç«¯å£è½¬å‘é€‰é¡¹ã€‚å®ƒæŒ‡ç¤ºsshåœ¨æœ¬åœ°ä¸»æœºçš„ç«¯å£6006ä¸Šç›‘å¬ï¼Œå¹¶å°†æ‰€æœ‰ä¼ å…¥çš„è¿æ¥è½¬å‘åˆ°è¿œç¨‹ä¸»æœºçš„127.0.0.1:6006ã€‚

root@ssh.intern-ai.org.cn: è¿™æ˜¯è¿œç¨‹ä¸»æœºçš„ç”¨æˆ·åå’Œä¸»æœºåã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œç”¨æˆ·åæ˜¯rootï¼Œä¸»æœºåæ˜¯ssh.intern-ai.org.cnã€‚

-p 38374: è¿™æ˜¯sshå‘½ä»¤çš„ç«¯å£é€‰é¡¹ã€‚å®ƒæŒ‡ç¤ºsshä½¿ç”¨38374ç«¯å£è¿æ¥åˆ°è¿œç¨‹ä¸»æœºã€‚
```
![ç«¯å£å·](image-17.png)

  - æ¨¡å‹åŠ è½½ä¸­
  ![åŠ è½½æ¨¡å‹](image-16.png)
  - åŠ è½½å®Œæˆç•Œé¢
  ![app](image-18.png)
  - å¯¹è¯
  ![å¯¹è¯](image-19.png)

### 3.3 Lagent æ™ºèƒ½ä½“

#### 3.3.1 å‰ç½®çŸ¥è¯†
  
  Lagent æ˜¯ä¸€ä¸ªè½»é‡çº§ã€å¼€æºçš„åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½ä½“ï¼ˆagentï¼‰æ¡†æ¶ï¼Œæ”¯æŒç”¨æˆ·å¿«é€Ÿåœ°å°†ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹è½¬å˜ä¸ºå¤šç§ç±»å‹çš„æ™ºèƒ½ä½“ï¼Œå¹¶æä¾›äº†ä¸€äº›å…¸å‹å·¥å…·ä¸ºå¤§è¯­è¨€æ¨¡å‹èµ‹èƒ½ã€‚å®ƒçš„æ•´ä¸ªæ¡†æ¶å›¾å¦‚ä¸‹:
  
  ![æ¶æ„](image-20.png)

#### 3.3.2 å®ç°è¿‡ç¨‹
  
##### 3.3.2.1 å¼€å‘æœºè®¾ç½®

- å¼€å¯ 30% A100
   
   åˆ›å»ºå¼€å‘æœºå‘½åä¸ºLagentProï¼Œé•œåƒé€‰æ‹©Cuda11.7ï¼Œèµ„æºé…ç½®ç°å­˜20Gï¼Œå†…å­˜72G

![åˆ›å»ºå¼€å‘æœº](image-21.png)

- è¿›å…¥å¼€å‘æœºï¼Œè¿›å…¥demoç¯å¢ƒ

```bash
conda activate demo
```
![demo conda](image-22.png)

- ä¸‹è½½Lagentæºç 

``` bash
cd /root/demo
git clone https://gitee.com/internlm/lagent.git
# git clone https://github.com/internlm/lagent.git
cd /root/demo/lagent
git checkout 581d9fb8987a5d9b72bb9ebd37a95efd47d479ac
pip install -e . # æºç å®‰è£…
```

![Lagentæºç ](image-23.png)

![å†…å®¹](image-24.png)

##### 3.3.2.2 ä½¿ç”¨Lagentè¿è¡ŒInternLM2å¤§æ¨¡å‹çš„æ™ºèƒ½ä½“

- æ„é€ è½¯é“¾æ¥å¿«æ·è®¿é—®æ–¹å¼

```bash
ln -s /root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-7b /root/models/internlm2-chat-7b
```
- ä¿®æ”¹lagentè·¯å¾„ä¸‹ examples/internlm2_agent_web_demo_hf.py è„šæœ¬æ¨¡å‹åŠ è½½è·¯å¾„

```python 
model_path = st.sidebar.text_input('æ¨¡å‹è·¯å¾„ï¼š', value='/root/models/internlm2-chat-7b')
```

![æ¨¡å‹è·¯å¾„](image-25.png)

- è¿è¡Œstreamlitå‰ç«¯é¡µé¢

```bash
streamlit run /root/demo/lagent/examples/internlm2_agent_web_demo_hf.py --server.address 127.0.0.1 --server.port 6006
```

![streamapp](image-26.png)

- æœ¬åœ°sshè¿æ¥è®¾ç½®

```bash
ssh -CNg -L 6006:127.0.0.1:6006 root@ssh.intern-ai.org.cn -p 41227
```

![ssh è¿æ¥](image-27.png)

- æœ¬åœ°è¿è¡Œstreamlit å‰ç«¯é¡µé¢

http://127.0.0.1:6006/

  - æ³¨æ„ï¼šè§‚å¯Ÿæ¨¡å‹åŠ è½½è¿›åº¦
  ![alt text](image-28.png)
  - æ³¨æ„å‹¾é€‰æ•°æ®åˆ†æï¼ˆå¯è§‚æµ‹Agentæ™ºèƒ½ä½“çš„è°ƒç”¨è¿‡ç¨‹â€”â€”è°ƒç”¨äº†ä»€ä¹ˆæ–¹æ³•ç»„åˆè¿›è¡Œè§£é¢˜ï¼‰
  ![alt text](image-29.png)

- è®©æ™ºèƒ½ä½“å‘Šè¯‰æˆ‘ä»–çš„èƒ½åŠ›å¹¶æµ‹éªŒèƒ½åŠ›

  Q:ä½ ä½œä¸ºAgentæ™ºèƒ½ä½“ï¼Œèƒ½ç»™æˆ‘ä¸€ä¸ªç¤ºä¾‹èƒ½ä½“ç°ä½ èƒ½åŠ›å—ï¼Ÿ
  A:![alt text](image-30.png)


#### 3.3.3 æºç è§£æ

``` python linenums="1"
import copy
import hashlib
import json
import os

import streamlit as st

from lagent.actions import ActionExecutor, ArxivSearch, IPythonInterpreter
from lagent.agents.internlm2_agent import INTERPRETER_CN, META_CN, PLUGIN_CN, Internlm2Agent, Internlm2Protocol
from lagent.llms import HFTransformer
from lagent.llms.meta_template import INTERNLM2_META as META
from lagent.schema import AgentStatusCode

# ä»streamlit.loggerå¯¼å…¥get_loggerå‡½æ•°ï¼Œä½†æœªä½¿ç”¨


class SessionState:
    def init_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡."""
        # åœ¨st.session_stateä¸­åˆ›å»º'assistant'å’Œ'user'åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†å²è®°å½•
        st.session_state['assistant'] = []
        st.session_state['user'] = []
        
        # åˆ›å»ºåŠ¨ä½œåˆ—è¡¨ï¼ŒåŒ…æ‹¬ArxivSearch()
        action_list = [
            ArxivSearch(),
        ]
        # åœ¨st.session_stateä¸­åˆ›å»º'plugin_map'å­—å…¸ï¼Œå°†åŠ¨ä½œåç§°æ˜ å°„åˆ°åŠ¨ä½œå¯¹è±¡
        st.session_state['plugin_map'] = {
            action.name: action
            for action in action_list
        }
        # åœ¨st.session_stateä¸­åˆ›å»ºç©ºçš„'model_map'å­—å…¸ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹å¯¹è±¡
        st.session_state['model_map'] = {}
        # åœ¨st.session_stateä¸­åˆ›å»º'model_selected'å˜é‡ï¼Œç”¨äºå­˜å‚¨å½“å‰é€‰æ‹©çš„æ¨¡å‹åç§°
        st.session_state['model_selected'] = None
        # åœ¨st.session_stateä¸­åˆ›å»ºç©ºçš„'plugin_actions'é›†åˆï¼Œç”¨äºå­˜å‚¨å½“å‰é€‰æ‹©çš„æ’ä»¶åŠ¨ä½œ
        st.session_state['plugin_actions'] = set()
        # åœ¨st.session_stateä¸­åˆ›å»ºç©ºçš„'history'åˆ—è¡¨ï¼Œç”¨äºå­˜å‚¨å¯¹è¯å†å²è®°å½•
        st.session_state['history'] = []

    def clear_state(self):
        """æ¸…é™¤ç°æœ‰çš„ä¼šè¯çŠ¶æ€."""
        # æ¸…ç©º'assistant'å’Œ'user'åˆ—è¡¨ï¼Œä»¥åŠ'model_selected'å˜é‡å’Œ'file'é›†åˆ
        st.session_state['assistant'] = []
        st.session_state['user'] = []
        st.session_state['model_selected'] = None
        st.session_state['file'] = set()
        # å¦‚æœ'chatbot'å­˜åœ¨äºst.session_stateä¸­ï¼Œåˆ™æ¸…ç©ºå…¶ä¼šè¯å†å²è®°å½•
        if 'chatbot' in st.session_state:
            st.session_state['chatbot']._session_history = []


class StreamlitUI:
    def __init__(self, session_state: SessionState):
        # åˆå§‹åŒ–StreamlitUIå¯¹è±¡ï¼Œå¹¶è®¾ç½®å…¶session_stateå±æ€§ä¸ºä¼ å…¥çš„SessionStateå¯¹è±¡
        self.init_streamlit()
        self.session_state = session_state

    def init_streamlit(self):
        """åˆå§‹åŒ–Streamlitçš„UIè®¾ç½®."""
        # è®¾ç½®é¡µé¢é…ç½®ï¼ŒåŒ…æ‹¬å¸ƒå±€ã€é¡µé¢æ ‡é¢˜å’Œé¡µé¢å›¾æ ‡
        st.set_page_config(
            layout='wide',
            page_title='lagent-web',
            page_icon='./docs/imgs/lagent_icon.png')
        # åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºæ ‡é¢˜å’Œåˆ†éš”çº¿
        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')
        # åœ¨ä¾§è¾¹æ ä¸Šæ˜¾ç¤ºæ ‡é¢˜
        st.sidebar.title('æ¨¡å‹æ§åˆ¶')
        # åœ¨st.session_stateä¸­åˆ›å»ºç©ºçš„'file'é›†åˆï¼Œç”¨äºå­˜å‚¨ä¸Šä¼ çš„æ–‡ä»¶
        st.session_state['file'] = set()
        # åœ¨st.session_stateä¸­åˆ›å»º'model_path'å˜é‡ï¼Œç”¨äºå­˜å‚¨æ¨¡å‹è·¯å¾„
        st.session_state['model_path'] = None

    def setup_sidebar(self):
        """è®¾ç½®ä¾§è¾¹æ ï¼Œç”¨äºæ¨¡å‹å’Œæ’ä»¶é€‰æ‹©."""
        # ä»ä¾§è¾¹æ è·å–æ¨¡å‹åç§°è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸º'internlm2-chat-7b'
        model_name = st.sidebar.text_input('æ¨¡å‹åç§°ï¼š', value='internlm2-chat-7b')
        # ä»ä¾§è¾¹æ è·å–ç³»ç»Ÿæç¤ºè¯è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸ºMETA_CN
        meta_prompt = st.sidebar.text_area('ç³»ç»Ÿæç¤ºè¯', value=META_CN)
        # ä»ä¾§è¾¹æ è·å–æ•°æ®åˆ†ææç¤ºè¯è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸ºINTERPRETER_CN
        da_prompt = st.sidebar.text_area('æ•°æ®åˆ†ææç¤ºè¯', value=INTERPRETER_CN)
        # ä»ä¾§è¾¹æ è·å–æ’ä»¶æç¤ºè¯è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸ºPLUGIN_CN
        plugin_prompt = st.sidebar.text_area('æ’ä»¶æç¤ºè¯', value=PLUGIN_CN)
        # ä»ä¾§è¾¹æ è·å–æ¨¡å‹è·¯å¾„è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸º'/root/models/internlm2-chat-7b'
        model_path = st.sidebar.text_input(
            'æ¨¡å‹è·¯å¾„ï¼š', value='/root/models/internlm2-chat-7b')
        
        # æ£€æŸ¥æ¨¡å‹åç§°æˆ–æ¨¡å‹è·¯å¾„æ˜¯å¦å·²æ›´æ”¹ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™åˆå§‹åŒ–æ–°æ¨¡å‹å¹¶æ¸…é™¤ä¼šè¯çŠ¶æ€
        if model_name != st.session_state['model_selected'] or st.session_state['model_path'] != model_path:
            st.session_state['model_path'] = model_path
            model = self.init_model(model_name, model_path)
            self.session_state.clear_state()
            st.session_state['model_selected'] = model_name
            if 'chatbot' in st.session_state:
                del st.session_state['chatbot']
        else:
            # å¦‚æœæ¨¡å‹æœªæ›´æ”¹ï¼Œåˆ™ä»st.session_stateä¸­çš„'model_map'å­—å…¸è·å–ç°æœ‰æ¨¡å‹å¯¹è±¡
            model = st.session_state['model_map'][model_name]
        
        # ä»ä¾§è¾¹æ è·å–æ’ä»¶åç§°çš„å¤šé€‰è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸ºç©ºåˆ—è¡¨
        plugin_name = st.sidebar.multiselect(
            'æ’ä»¶é€‰æ‹©',
            options=list(st.session_state['plugin_map'].keys()),
            default=[],
        )
        # ä»ä¾§è¾¹æ è·å–æ•°æ®åˆ†æçš„å¤é€‰æ¡†è¾“å…¥ï¼Œé»˜è®¤å€¼ä¸ºFalse
        da_flag = st.sidebar.checkbox(
            'æ•°æ®åˆ†æ',
            value=False,
        )
        # ä»æ’ä»¶åç§°åˆ—è¡¨ä¸­è·å–æ’ä»¶åŠ¨ä½œåˆ—è¡¨
        plugin_action = [
            st.session_state['plugin_map'][name] for name in plugin_name
        ]
        
        # å¦‚æœ'chatbot'å­˜åœ¨äºst.session_stateä¸­ï¼Œåˆ™æ ¹æ®é€‰æ‹©çš„æ’ä»¶å’Œæ•°æ®åˆ†æè®¾ç½®æ›´æ–°å…¶å±æ€§
        if 'chatbot' in st.session_state:
            if len(plugin_action) > 0:
                # å¦‚æœé€‰æ‹©äº†æ’ä»¶ï¼Œåˆ™åˆ›å»ºActionExecutorå¯¹è±¡å¹¶è®¾ç½®chatbotçš„_action_executorå±æ€§ä¸ºè¯¥å¯¹è±¡
                st.session_state['chatbot']._action_executor = ActionExecutor(actions=plugin_action)
            else:
                # å¦‚æœæ²¡æœ‰é€‰æ‹©æ’ä»¶ï¼Œåˆ™å°†chatbotçš„_action_executorå±æ€§è®¾ç½®ä¸ºNone
                st.session_state['chatbot']._action_executor = None
            if da_flag:
                # å¦‚æœé€‰æ‹©äº†æ•°æ®åˆ†æï¼Œåˆ™åˆ›å»ºActionExecutorå¯¹è±¡å¹¶è®¾ç½®chatbotçš„_interpreter_executorå±æ€§ä¸ºè¯¥å¯¹è±¡
                st.session_state['chatbot']._interpreter_executor = ActionExecutor(actions=[IPythonInterpreter()])
            else:
                # å¦‚æœæ²¡æœ‰é€‰æ‹©æ•°æ®åˆ†æï¼Œåˆ™å°†chatbotçš„_interpreter_executorå±æ€§è®¾ç½®ä¸ºNone
                st.session_state['chatbot']._interpreter_executor = None
            # æ›´æ–°chatbotçš„æç¤ºè¯å±æ€§ä¸ºä¾§è¾¹æ è¾“å…¥çš„å€¼
            st.session_state['chatbot']._protocol._meta_template = meta_prompt
            st.session_state['chatbot']._protocol.plugin_prompt = plugin_prompt
            st.session_state['chatbot']._protocol.interpreter_prompt = da_prompt
        if st.sidebar.button('æ¸…ç©ºå¯¹è¯', key='clear'):
            # å¦‚æœç‚¹å‡»äº†ä¾§è¾¹æ ä¸Šçš„â€œæ¸…ç©ºå¯¹è¯â€æŒ‰é’®ï¼Œåˆ™è°ƒç”¨SessionStateå¯¹è±¡çš„clear_stateæ–¹æ³•æ¥æ¸…é™¤ä¼šè¯çŠ¶æ€
            self.session_state.clear_state()
        # ä»ä¾§è¾¹æ è·å–æ–‡ä»¶ä¸Šä¼ å™¨è¾“å…¥ï¼Œç”¨äºä¸Šä¼ æ–‡ä»¶åˆ°åº”ç”¨ç¨‹åºä¸­ä½¿ç”¨
        uploaded_file = st.sidebar.file_uploader('ä¸Šä¼ æ–‡ä»¶')
        return model_name, model, plugin_action, uploaded_file, model_path
    
    def init_model(self, model_name, path):
        """æ ¹æ®è¾“å…¥çš„æ¨¡å‹åç§°åˆå§‹åŒ–æ¨¡å‹."""
        # ä½¿ç”¨HFTransformerç±»åˆå§‹åŒ–æ¨¡å‹å¯¹è±¡ï¼Œå¹¶å°†æ¨¡å‹è·¯å¾„å’Œå…¶ä»–å‚æ•°ä¼ é€’ç»™æ„é€ å‡½æ•°ã€‚å°†æ¨¡å‹å¯¹è±¡å­˜å‚¨åœ¨st.session_stateä¸­çš„'model_map'å­—å…¸ä¸­ã€‚
        st.session_state['model_map'][model_name] = HFTransformer(path=path, meta_template=META, max_new_tokens=1024, top_p=0.8, top_k=None, temperature=0.1, repetition_penalty=1.0, stop_words=['<|im_end|>'])
        return st.session_state['model_map'][model_name]
    def initialize_chatbot(self, model, plugin_action):
    """ä½¿ç”¨ç»™å®šçš„æ¨¡å‹å’Œæ’ä»¶åŠ¨ä½œåˆå§‹åŒ–èŠå¤©æœºå™¨äºº."""
    # ä½¿ç”¨Internlm2Agentç±»åˆå§‹åŒ–èŠå¤©æœºå™¨äººå¯¹è±¡ï¼Œå¹¶å°†LLMï¼ˆè¯­è¨€æ¨¡å‹ï¼‰ã€åè®®å’Œæœ€å¤§å›åˆæ•°ä¼ é€’ç»™æ„é€ å‡½æ•°ã€‚è¿”å›èŠå¤©æœºå™¨äººå¯¹è±¡ã€‚
    return Internlm2Agent(
        llm=model,
        protocol=Internlm2Protocol(
            tool=dict(
                begin='{start_token}{name}\n',
                start_token='<|action_start|>',
                name_map=dict(
                    plugin='<|plugin|>', interpreter='<|interpreter|>'),
                belong='assistant',
                end='<|action_end|>\n',
            ), ),
        max_turn=7)

def render_user(self, prompt: str):
    # ä½¿ç”¨st.chat_message('user')åœ¨èŠå¤©çª—å£ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„ç”¨æˆ·æ¶ˆæ¯ï¼Œå¹¶ä½¿ç”¨st.markdown(prompt)æ˜¾ç¤ºæç¤ºæ–‡æœ¬ã€‚
    with st.chat_message('user'):
        st.markdown(prompt)

def render_assistant(self, agent_return):
    # ä½¿ç”¨st.chat_message('assistant')åœ¨èŠå¤©çª—å£ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„åŠ©æ‰‹æ¶ˆæ¯ï¼Œå¹¶è¿­ä»£agent_returnä¸­çš„actionsã€‚å¯¹äºæ¯ä¸ªä¸æ˜¯FinishActionçš„éç©ºåŠ¨ä½œï¼Œè°ƒç”¨render_actionæ–¹æ³•æ¥æ˜¾ç¤ºå®ƒã€‚æœ€åï¼Œä½¿ç”¨st.markdown(agent_return.response)æ˜¾ç¤ºagent_returnçš„å“åº”ã€‚
    with st.chat_message('assistant'):
        for action in agent_return.actions:
            if (action) and (action.type != 'FinishAction'):
                self.render_action(action)
        st.markdown(agent_return.response)

def render_plugin_args(self, action):
    # ä»åŠ¨ä½œä¸­è·å–åŠ¨ä½œåç§°å’Œå‚æ•°ï¼Œå¹¶å°†å®ƒä»¬è½¬æ¢ä¸ºJSONæ ¼å¼çš„å­—ç¬¦ä¸²ã€‚ä½¿ç”¨st.markdownæ˜¾ç¤ºè¯¥å­—ç¬¦ä¸²ã€‚
    action_name = action.type
    args = action.args
    import json
    parameter_dict = dict(name=action_name, parameters=args)
    parameter_str = '```json\n' + json.dumps(parameter_dict, indent=4, ensure_ascii=False) + '\n```'
    st.markdown(parameter_str)

def render_interpreter_args(self, action):
    # ä½¿ç”¨st.infoæ˜¾ç¤ºåŠ¨ä½œç±»å‹ï¼Œå¹¶ä½¿ç”¨st.markdownæ˜¾ç¤ºåŠ¨ä½œå‚æ•°ä¸­çš„æ–‡æœ¬ã€‚
    st.info(action.type)
    st.markdown(action.args['text'])

def render_action(self, action):
    # ä½¿ç”¨st.markdownæ˜¾ç¤ºåŠ¨ä½œçš„thoughtå±æ€§ã€‚å¦‚æœåŠ¨ä½œç±»å‹æ˜¯IPythonInterpreterï¼Œåˆ™è°ƒç”¨render_interpreter_argsæ–¹æ³•æ¥æ˜¾ç¤ºå‚æ•°ã€‚å¦åˆ™ï¼Œå¦‚æœåŠ¨ä½œç±»å‹ä¸æ˜¯FinishActionï¼Œåˆ™è°ƒç”¨render_plugin_argsæ–¹æ³•æ¥æ˜¾ç¤ºå‚æ•°ã€‚æœ€åï¼Œè°ƒç”¨render_action_resultsæ–¹æ³•æ¥æ˜¾ç¤ºåŠ¨ä½œçš„ç»“æœã€‚
    st.markdown(action.thought)
    if action.type == 'IPythonInterpreter':
        self.render_interpreter_args(action)
    elif action.type == 'FinishAction':
        pass
    else:
        self.render_plugin_args(action)
    self.render_action_results(action)

def render_action_results(self, action):
    """æ˜¾ç¤ºåŠ¨ä½œçš„ç»“æœï¼ŒåŒ…æ‹¬æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘å’ŒéŸ³é¢‘."""
    # å¦‚æœåŠ¨ä½œç»“æœæ˜¯å­—å…¸ï¼Œåˆ™æ£€æŸ¥å®ƒæ˜¯å¦åŒ…å«æ–‡æœ¬ã€å›¾åƒã€è§†é¢‘æˆ–éŸ³é¢‘ï¼Œå¹¶ä½¿ç”¨ç›¸åº”çš„stæ–¹æ³•æ˜¾ç¤ºå®ƒä»¬ã€‚å¦‚æœç»“æœæ˜¯åˆ—è¡¨ï¼Œåˆ™è¿­ä»£æ¯ä¸ªé¡¹ç›®ï¼Œå¹¶æ ¹æ®å…¶ç±»å‹æ˜¾ç¤ºç›¸åº”çš„å†…å®¹ã€‚å¦‚æœåŠ¨ä½œæœ‰é”™è¯¯æ¶ˆæ¯ï¼Œåˆ™ä½¿ç”¨st.erroræ˜¾ç¤ºå®ƒã€‚
    if (isinstance(action.result, dict)):
        if 'text' in action.result:
            st.markdown('```\n' + action.result['text'] + '\n```')
        if 'image' in action.result:
            # image_path = action.result['image']
            for image_path in action.result['image']:
                image_data = open(image_path, 'rb').read()
                st.image(image_data, caption='Generated Image')
        if 'video' in action.result:
            video_data = action.result['video']
            video_data = open(video_data, 'rb').read()
            st.video(video_data)
        if 'audio' in action.result:
            audio_data = action.result['audio']
            audio_data = open(audio_data, 'rb').read()
            st.audio(audio_data)
    elif isinstance(action.result, list):
        for item in action.result:
            if item['type'] == 'text':
                st.markdown('```\n' + item['content'] + '\n```')
            elif item['type'] == 'image':
                image_data = open(item['content'], 'rb').read()
                st.image(image_data, caption='Generated Image')
            elif item['type'] == 'video':
                video_data = open(item['content'], 'rb').read()
                st.video(video_data)
            elif item['type'] == 'audio':
                audio_data = open(item['content'], 'rb').read()
                st.audio(audio_data)
    if action.errmsg:
        st.error(action.errmsg)
def main():
    # å¦‚æœ'ui'ä¸åœ¨st.session_stateä¸­ï¼Œåˆ™åˆå§‹åŒ–SessionStateå¯¹è±¡å’ŒStreamlitUIå¯¹è±¡ï¼Œå¹¶å°†å®ƒä»¬å­˜å‚¨åœ¨st.session_stateä¸­ã€‚å¦åˆ™ï¼Œè®¾ç½®é¡µé¢é…ç½®å¹¶æ˜¾ç¤ºæ ‡é¢˜å’Œåˆ†éš”çº¿ã€‚ç„¶åï¼Œè°ƒç”¨StreamlitUIå¯¹è±¡çš„setup_sidebaræ–¹æ³•æ¥è®¾ç½®ä¾§è¾¹æ ã€‚æ¥ä¸‹æ¥ï¼Œæ£€æŸ¥'chatbot'æ˜¯å¦å­˜åœ¨äºst.session_stateä¸­ï¼Œæˆ–è€…æ¨¡å‹æ˜¯å¦å·²æ›´æ”¹ã€‚å¦‚æœæ˜¯ï¼Œåˆ™è°ƒç”¨initialize_chatbotæ–¹æ³•æ¥åˆå§‹åŒ–èŠå¤©æœºå™¨äººï¼Œå¹¶å°†ä¼šè¯å†å²è®°å½•è®¾ç½®ä¸ºç©ºåˆ—è¡¨ã€‚æœ€åï¼Œè¿­ä»£ä¼šè¯çŠ¶æ€ä¸­çš„ç”¨æˆ·æç¤ºå’Œä»£ç†è¿”å›ï¼Œå¹¶è°ƒç”¨ç›¸åº”çš„renderæ–¹æ³•æ¥æ˜¾ç¤ºå®ƒä»¬ã€‚ç”±äºä»£ç ç‰‡æ®µä¸å®Œæ•´ï¼Œæ— æ³•æä¾›å®Œæ•´çš„mainå‡½æ•°æ³¨é‡Šã€‚è¯·æ³¨æ„ï¼Œæ‚¨å¯èƒ½éœ€è¦æä¾›ç¼ºå°‘çš„ä»£ç å’Œå˜é‡ä»¥ä½¿mainå‡½æ•°æ­£å¸¸å·¥ä½œã€‚
    if 'ui' not in st.session_state:
        session_state = SessionState()
        session_state.init_state()
        st.session_state['ui'] = StreamlitUI(session_state)
    else:
        st.set_page_config(layout='wide', page_title='lagent-web', page_icon='./docs/imgs/lagent_icon.png')
        st.header(':robot_face: :blue[Lagent] Web Demo ', divider='rainbow')
    _, model, plugin_action, uploaded_file, _ = st.session_state['ui'].setup_sidebar()
    if 'chatbot' not in st.session_state or model != st.session_state['chatbot']._llm:
        st.session_state['chatbot'] = st.session_state['ui'].initialize_chatbot(model, plugin_action)
        st.session_state['session_history'] = []
    for prompt, agent_return in zip(st.session_state['user'], st.session_state['assistant']): # å‡è®¾è¿™äº›å˜é‡å­˜åœ¨äºä¼šè¯çŠ¶æ€ä¸­å¹¶åŒ…å«é€‚å½“çš„å€¼ã€‚æ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„åº”ç”¨ç¨‹åºé€»è¾‘è¿›è¡Œè°ƒæ•´ã€‚
        st.session_state['ui'].render_user(prompt) # æ˜¾ç¤ºç”¨æˆ·æç¤ºã€‚æ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„åº”ç”¨ç¨‹åºé€»è¾‘è¿›è¡Œè°ƒæ•´ã€‚
        st.session_state['ui'].render_assistant(agent_return) # æ˜¾ç¤ºä»£ç†è¿”å›ã€‚æ‚¨å¯èƒ½éœ€è¦æ ¹æ®æ‚¨çš„åº”ç”¨ç¨‹åºé€»è¾‘è¿›è¡Œè°ƒæ•´
```

### 3.4 å¤šæ¨¡æ€Xomposer ï¼ˆçµç¬”Â·2ï¼‰

#### 3.4.1 å‰ç½®çŸ¥è¯†

[Xomposeråœ°å€](https://github.com/InternLM/InternLM-XComposer/blob/main/README_CN.md)

[è®ºæ–‡åœ°å€](https://arxiv.org/abs/2401.16420)

[è®ºæ–‡pdf](2401.16420.pdf)

>æµ¦è¯­Â·çµç¬”2æ˜¯åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­2å¤§è¯­è¨€æ¨¡å‹ç ”å‘çš„çªç ´æ€§çš„å›¾æ–‡å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå…·æœ‰éå‡¡çš„å›¾æ–‡å†™ä½œå’Œå›¾åƒç†è§£èƒ½åŠ›ï¼Œåœ¨å¤šç§åº”ç”¨åœºæ™¯è¡¨ç°å‡ºè‰²ï¼š
> - **è‡ªç”±æŒ‡ä»¤è¾“å…¥çš„å›¾æ–‡å†™ä½œ**ï¼š æµ¦è¯­Â·çµç¬”2å¯ä»¥ç†è§£*è‡ªç”±å½¢å¼çš„å›¾æ–‡æŒ‡ä»¤è¾“å…¥*ï¼ŒåŒ…æ‹¬*å¤§çº²ã€æ–‡ç« ç»†èŠ‚è¦æ±‚ã€å‚è€ƒå›¾ç‰‡*ç­‰ï¼Œä¸ºç”¨æˆ·æ‰“é€ å›¾æ–‡å¹¶è²Œçš„ä¸“å±æ–‡ç« ã€‚ç”Ÿæˆçš„æ–‡ç« æ–‡é‡‡æ–ç„¶ï¼Œå›¾æ–‡ç›¸å¾—ç›Šå½°ï¼Œæä¾›æ²‰æµ¸å¼çš„é˜…è¯»ä½“éªŒã€‚
>- **å‡†ç¡®çš„å›¾æ–‡é—®é¢˜è§£ç­”**ï¼š æµ¦è¯­Â·çµç¬”2å…·æœ‰æµ·é‡å›¾æ–‡çŸ¥è¯†ï¼Œå¯ä»¥å‡†ç¡®çš„å›å¤å„ç§å›¾æ–‡é—®ç­”éš¾é¢˜ï¼Œåœ¨*è¯†åˆ«ã€æ„ŸçŸ¥ã€ç»†èŠ‚æè¿°ã€è§†è§‰æ¨ç†*ç­‰èƒ½åŠ›ä¸Šè¡¨ç°æƒŠäººã€‚
>- **æ°å‡ºæ€§èƒ½**ï¼š æµ¦è¯­Â·çµç¬”2åŸºäºä¹¦ç”ŸÂ·æµ¦è¯­2-7Bæ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨13é¡¹å¤šæ¨¡æ€è¯„æµ‹ä¸­å¤§å¹…é¢†å…ˆåŒé‡çº§å¤šæ¨¡æ€æ¨¡å‹ï¼Œåœ¨å…¶ä¸­6é¡¹è¯„æµ‹ä¸­è¶…è¿‡ GPT-4V å’Œ Gemini Proã€‚


---

- æ¨¡å‹åˆé›†

| æ¨¡å‹                        | ç”¨é€”                | Transformers(HF)                                                                           | ModelScope(HF)                                                                                                                                                               | å¼€æºæ—¥æœŸ   |
| --------------------------- | ------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------- |
| **InternLM-XComposer2**     | å›¾æ–‡åˆ›ä½œ            | [ğŸ¤—internlm-xcomposer2-7b](https://huggingface.co/internlm/internlm-xcomposer2-7b)         | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b/summary)         | 2024-01-26 |
| **InternLM-XComposer2-VL**  | Benchmark, è§†è§‰é—®ç­” | [ğŸ¤—internlm-xcomposer2-vl-7b](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b)   | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-vl-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b/summary)   | 2024-01-26 |
| **InternLM-XComposer2-4bit**  |  å›¾æ–‡åˆ›ä½œ   | [ğŸ¤—internlm-xcomposer2-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer2-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-7b-4bit/summary) |  2024-02-06   |
| **InternLM-XComposer2-VL-4bit**   | Benchmark, è§†è§‰é—®ç­”   | [ğŸ¤—internlm-xcomposer2-vl-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer2-vl-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer2-vl-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer2-vl-7b-4bit/summary) |  2024-02-06   |
| **InternLM-XComposer**      | å›¾æ–‡åˆ›ä½œ, è§†è§‰é—®ç­”  | [ğŸ¤—internlm-xcomposer-7b](https://huggingface.co/internlm/internlm-xcomposer-7b)           | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b/summary)           | 2023-09-26 |
| **InternLM-XComposer-4bit** | å›¾æ–‡åˆ›ä½œ, è§†è§‰é—®ç­”  | [ğŸ¤—internlm-xcomposer-7b-4bit](https://huggingface.co/internlm/internlm-xcomposer-7b-4bit) | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-7b-4bit](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-7b-4bit/summary) | 2023-09-26 |
| **InternLM-XComposer-VL**   | Benchmark           | [ğŸ¤—internlm-xcomposer-vl-7b](https://huggingface.co/internlm/internlm-xcomposer-vl-7b)     | [<img src="./assets/modelscope_logo.png" width="20px" /> internlm-xcomposer-vl-7b](https://modelscope.cn/models/Shanghai_AI_Laboratory/internlm-xcomposer-vl-7b/summary)     | 2023-09-26 |

#### 3.4.2 å®ç°è¿‡ç¨‹