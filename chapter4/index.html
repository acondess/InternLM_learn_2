
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../chapter3/">
      
      
        <link rel="next" href="../chapter5/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.0, mkdocs-material-9.5.22">
    
    
      
        <title>课时四 XTuner微调多模态Agent - 第二期书生·浦语实战营学习笔记及作业提交</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.732c4fb1.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#xtuneragent" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href=".." title="第二期书生·浦语实战营学习笔记及作业提交" class="md-header__button md-logo" aria-label="第二期书生·浦语实战营学习笔记及作业提交" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            第二期书生·浦语实战营学习笔记及作业提交
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              课时四 XTuner微调多模态Agent
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="purple"  aria-label="switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="lime"  aria-label="switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6m0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4m0-7c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href=".." class="md-tabs__link">
        
  
    
  
  第二期书生·浦语实战营学习笔记及作业提交

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter1/" class="md-tabs__link">
        
  
    
  
  课时一 书生·浦语大模型全链路开源开放体系

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter2/" class="md-tabs__link">
        
  
    
  
  课时二 轻松分钟玩转书生·浦语大模型趣味 Demo

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter3/" class="md-tabs__link">
        
  
    
  
  课时三 "茴香豆":零代码搭建你的 RAG 智能助理

      </a>
    </li>
  

      
        
  
  
    
  
  
    <li class="md-tabs__item md-tabs__item--active">
      <a href="./" class="md-tabs__link">
        
  
    
  
  课时四 XTuner微调多模态Agent

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter5/" class="md-tabs__link">
        
  
    
  
  课时五 LMDeploy量化部署LLM实践

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter6/" class="md-tabs__link">
        
  
    
  
  课时六 Lagent &amp; AgentLego 智能体应用搭建

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../chapter7/" class="md-tabs__link">
        
  
    
  
  课时七 OpenCompass 大模型测评

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="第二期书生·浦语实战营学习笔记及作业提交" class="md-nav__button md-logo" aria-label="第二期书生·浦语实战营学习笔记及作业提交" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    第二期书生·浦语实战营学习笔记及作业提交
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    第二期书生·浦语实战营学习笔记及作业提交
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时一 书生·浦语大模型全链路开源开放体系
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时二 轻松分钟玩转书生·浦语大模型趣味 Demo
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时三 "茴香豆":零代码搭建你的 RAG 智能助理
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    课时四 XTuner微调多模态Agent
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    课时四 XTuner微调多模态Agent
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    <span class="md-ellipsis">
      1. 提交的作业结果
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 提交的作业结果">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11" class="md-nav__link">
    <span class="md-ellipsis">
      1.1 训练自己的小助手认知（记录复现过程并截图）
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#12-openxlab-openxlab" class="md-nav__link">
    <span class="md-ellipsis">
      1.2 将自我认知的模型上传到 OpenXLab，并将应用部署到 OpenXLab
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#13" class="md-nav__link">
    <span class="md-ellipsis">
      1.3 复现多模态微调
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    <span class="md-ellipsis">
      2. 文档复现笔记
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. 文档复现笔记">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#21" class="md-nav__link">
    <span class="md-ellipsis">
      2.1 前置知识
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#22" class="md-nav__link">
    <span class="md-ellipsis">
      2.2 复现步骤
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2 复现步骤">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#221" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.1 环境配置
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#222" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2 微调
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2.2 微调">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2221" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.1 准备配置文件
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2222" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.2 模型设置
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2223" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.3 数据集下载
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2224" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.4 修改配置文件
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2225" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.5 开始微调
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2226-pthlora" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.2.6 转换PTH模型为LoRA模型
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#223" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.3 部署&amp;测试
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2.3 部署&测试">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2231-hfadapter" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.3.1 合并hf的adapter到大模型
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2232" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.3.2 与合并后的模型对话
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2233-cli_demopy" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.3.3 运行测试cli_demo.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#224-openxlab" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.4 模型&amp;应用部署到OpenXLab
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#225" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.5 多模态微调
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2.2.5 多模态微调">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#2251" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.5.1 环境设置
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2252" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.5.2 预训练
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2253" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.5.3 微调
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2254" class="md-nav__link">
    <span class="md-ellipsis">
      2.2.5.4 微调模型对话
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    <span class="md-ellipsis">
      3. 视频总结
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时五 LMDeploy量化部署LLM实践
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter6/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时六 Lagent &amp; AgentLego 智能体应用搭建
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../chapter7/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    课时七 OpenCompass 大模型测评
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="xtuneragent">课时四 XTuner微调多模态Agent</h1>
<p><img alt="alt text" src="../image-93.png" /></p>
<p><a href="https://aicarrier.feishu.cn/wiki/Vv4swUFMni5DiMkcasUczUp9nid#LSBkd2cTHorhsAx5jZAcO0B3nqe">飞书地址</a></p>
<p><a href="https://studio.intern-ai.org.cn/">算力平台</a></p>
<h2 id="1">1. 提交的作业结果</h2>
<p><a href="https://github.com/InternLM/Tutorial/blob/camp2/xtuner/homework.md">作业要求</a></p>
<h3 id="11">1.1 训练自己的小助手认知（记录复现过程并截图）</h3>
<ul>
<li>训练完小助手对话截图：</li>
</ul>
<p><img alt="alt text" src="../image-112.png" />
- 复现笔记：
<a href="#2-文档复现笔记">复现步骤</a></p>
<h3 id="12-openxlab-openxlab">1.2 将自我认知的模型上传到 OpenXLab，并将应用部署到 OpenXLab</h3>
<h3 id="13">1.3  复现多模态微调</h3>
<ul>
<li>复现结果截图</li>
</ul>
<p><img alt="alt text" src="../image-221.png" /></p>
<ul>
<li>复现过程文档</li>
</ul>
<p><a href="#225-多模态微调">多模态微调复现</a></p>
<h2 id="2">2. 文档复现笔记</h2>
<p><a href="https://github.com/InternLM/tutorial/blob/main/xtuner/README.md">文档地址</a></p>
<h3 id="21">2.1 前置知识</h3>
<h3 id="22">2.2 复现步骤</h3>
<h4 id="221">2.2.1 环境配置</h4>
<ul>
<li>创建开发机</li>
</ul>
<p><img alt="alt text" src="../image-94.png" /></p>
<ul>
<li>进入开发机创建conda环境</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="nb">cd</span><span class="w"> </span>/root
<a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>/share/install_conda_env_internlm_base.sh<span class="w"> </span>xtuner0.1.9
</code></pre></div>
<p><img alt="alt text" src="../image-95.png" /></p>
<ul>
<li>激活xtuner0.1.9环境&amp;创建文件夹</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a>conda<span class="w"> </span>activate<span class="w"> </span>xtuner0.1.9
<a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="nb">cd</span><span class="w"> </span>/root
<a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a>mkdir<span class="w"> </span>xtuner019<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>xtuner019
</code></pre></div>
<p><img alt="alt text" src="../image-96.png" /></p>
<ul>
<li>获取0.1.9版本源码</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>git<span class="w"> </span>clone<span class="w"> </span>-b<span class="w"> </span>v0.1.9<span class="w">  </span>https://github.com/InternLM/xtuner
</code></pre></div>
<img alt="alt text" src="../image-97.png" /></p>
<ul>
<li>从源码安装Xtuner</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="nb">cd</span><span class="w"> </span>xtuner
<a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;.[all]&#39;</span>
</code></pre></div>
<p><img alt="alt text" src="../image-98.png" /></p>
<ul>
<li>创建数据集文件夹地址</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># 创建一个微调 oasst1 数据集的工作路径，进入</span>
<a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>mkdir<span class="w"> </span>~/ft-oasst1<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>~/ft-oasst1
</code></pre></div>
<p><img alt="alt text" src="../image-99.png" /></p>
<h4 id="222">2.2.2 微调</h4>
<h5 id="2221">2.2.2.1 准备配置文件</h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># 列出所有内置配置</span>
<a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>xtuner<span class="w"> </span>list-cfg
</code></pre></div>
<blockquote>
<p>假如显示bash: xtuner: command not found的话可以考虑在终端输入 export PATH=$PATH:'/root/.local/bin'</p>
</blockquote>
<p>我是又执行了一遍源码安装命令</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="nb">cd</span><span class="w"> </span>xtuner
<a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;.[all]&#39;</span>
</code></pre></div>
<ul>
<li>配置文件
<div class="highlight"><pre><span></span><code><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>xtuner<span class="w"> </span>list-cfg
</code></pre></div></li>
</ul>
<p><img alt="alt text" src="../image-100.png" /></p>
<details>
<summary>展开内容</summary>
<div class="highlight"><pre><span></span><code><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="o">==========================</span><span class="nv">CONFIGS</span><span class="o">===========================</span>
<a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>baichuan2_13b_base_qlora_alpaca_e3
<a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>baichuan2_13b_base_qlora_alpaca_enzh_e3
<a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>baichuan2_13b_base_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>baichuan2_13b_base_qlora_alpaca_zh_e3
<a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>baichuan2_13b_base_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>baichuan2_13b_base_qlora_code_alpaca_e3
<a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>baichuan2_13b_base_qlora_colorist_e5
<a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>baichuan2_13b_base_qlora_lawyer_e3
<a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>baichuan2_13b_base_qlora_oasst1_512_e3
<a id="__codelineno-8-11" name="__codelineno-8-11" href="#__codelineno-8-11"></a>baichuan2_13b_base_qlora_oasst1_e3
<a id="__codelineno-8-12" name="__codelineno-8-12" href="#__codelineno-8-12"></a>baichuan2_13b_base_qlora_open_platypus_e3
<a id="__codelineno-8-13" name="__codelineno-8-13" href="#__codelineno-8-13"></a>baichuan2_13b_base_qlora_sql_e3
<a id="__codelineno-8-14" name="__codelineno-8-14" href="#__codelineno-8-14"></a>baichuan2_13b_chat_qlora_alpaca_e3
<a id="__codelineno-8-15" name="__codelineno-8-15" href="#__codelineno-8-15"></a>baichuan2_13b_chat_qlora_alpaca_enzh_e3
<a id="__codelineno-8-16" name="__codelineno-8-16" href="#__codelineno-8-16"></a>baichuan2_13b_chat_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-17" name="__codelineno-8-17" href="#__codelineno-8-17"></a>baichuan2_13b_chat_qlora_alpaca_zh_e3
<a id="__codelineno-8-18" name="__codelineno-8-18" href="#__codelineno-8-18"></a>baichuan2_13b_chat_qlora_code_alpaca_e3
<a id="__codelineno-8-19" name="__codelineno-8-19" href="#__codelineno-8-19"></a>baichuan2_13b_chat_qlora_lawyer_e3
<a id="__codelineno-8-20" name="__codelineno-8-20" href="#__codelineno-8-20"></a>baichuan2_13b_chat_qlora_oasst1_512_e3
<a id="__codelineno-8-21" name="__codelineno-8-21" href="#__codelineno-8-21"></a>baichuan2_13b_chat_qlora_oasst1_e3
<a id="__codelineno-8-22" name="__codelineno-8-22" href="#__codelineno-8-22"></a>baichuan2_13b_chat_qlora_open_platypus_e3
<a id="__codelineno-8-23" name="__codelineno-8-23" href="#__codelineno-8-23"></a>baichuan2_7b_base_qlora_alpaca_e3
<a id="__codelineno-8-24" name="__codelineno-8-24" href="#__codelineno-8-24"></a>baichuan2_7b_base_qlora_alpaca_enzh_e3
<a id="__codelineno-8-25" name="__codelineno-8-25" href="#__codelineno-8-25"></a>baichuan2_7b_base_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-26" name="__codelineno-8-26" href="#__codelineno-8-26"></a>baichuan2_7b_base_qlora_alpaca_zh_e3
<a id="__codelineno-8-27" name="__codelineno-8-27" href="#__codelineno-8-27"></a>baichuan2_7b_base_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-28" name="__codelineno-8-28" href="#__codelineno-8-28"></a>baichuan2_7b_base_qlora_code_alpaca_e3
<a id="__codelineno-8-29" name="__codelineno-8-29" href="#__codelineno-8-29"></a>baichuan2_7b_base_qlora_colorist_e5
<a id="__codelineno-8-30" name="__codelineno-8-30" href="#__codelineno-8-30"></a>baichuan2_7b_base_qlora_lawyer_e3
<a id="__codelineno-8-31" name="__codelineno-8-31" href="#__codelineno-8-31"></a>baichuan2_7b_base_qlora_oasst1_512_e3
<a id="__codelineno-8-32" name="__codelineno-8-32" href="#__codelineno-8-32"></a>baichuan2_7b_base_qlora_oasst1_e3
<a id="__codelineno-8-33" name="__codelineno-8-33" href="#__codelineno-8-33"></a>baichuan2_7b_base_qlora_open_platypus_e3
<a id="__codelineno-8-34" name="__codelineno-8-34" href="#__codelineno-8-34"></a>baichuan2_7b_base_qlora_sql_e3
<a id="__codelineno-8-35" name="__codelineno-8-35" href="#__codelineno-8-35"></a>baichuan2_7b_chat_qlora_alpaca_e3
<a id="__codelineno-8-36" name="__codelineno-8-36" href="#__codelineno-8-36"></a>baichuan2_7b_chat_qlora_alpaca_enzh_e3
<a id="__codelineno-8-37" name="__codelineno-8-37" href="#__codelineno-8-37"></a>baichuan2_7b_chat_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-38" name="__codelineno-8-38" href="#__codelineno-8-38"></a>baichuan2_7b_chat_qlora_alpaca_zh_e3
<a id="__codelineno-8-39" name="__codelineno-8-39" href="#__codelineno-8-39"></a>baichuan2_7b_chat_qlora_code_alpaca_e3
<a id="__codelineno-8-40" name="__codelineno-8-40" href="#__codelineno-8-40"></a>baichuan2_7b_chat_qlora_lawyer_e3
<a id="__codelineno-8-41" name="__codelineno-8-41" href="#__codelineno-8-41"></a>baichuan2_7b_chat_qlora_oasst1_512_e3
<a id="__codelineno-8-42" name="__codelineno-8-42" href="#__codelineno-8-42"></a>baichuan2_7b_chat_qlora_oasst1_e3
<a id="__codelineno-8-43" name="__codelineno-8-43" href="#__codelineno-8-43"></a>baichuan2_7b_chat_qlora_open_platypus_e3
<a id="__codelineno-8-44" name="__codelineno-8-44" href="#__codelineno-8-44"></a>baichuan_13b_base_qlora_alpaca_e3
<a id="__codelineno-8-45" name="__codelineno-8-45" href="#__codelineno-8-45"></a>baichuan_13b_base_qlora_alpaca_enzh_e3
<a id="__codelineno-8-46" name="__codelineno-8-46" href="#__codelineno-8-46"></a>baichuan_13b_base_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-47" name="__codelineno-8-47" href="#__codelineno-8-47"></a>baichuan_13b_base_qlora_alpaca_zh_e3
<a id="__codelineno-8-48" name="__codelineno-8-48" href="#__codelineno-8-48"></a>baichuan_13b_base_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-49" name="__codelineno-8-49" href="#__codelineno-8-49"></a>baichuan_13b_base_qlora_code_alpaca_e3
<a id="__codelineno-8-50" name="__codelineno-8-50" href="#__codelineno-8-50"></a>baichuan_13b_base_qlora_colorist_e5
<a id="__codelineno-8-51" name="__codelineno-8-51" href="#__codelineno-8-51"></a>baichuan_13b_base_qlora_lawyer_e3
<a id="__codelineno-8-52" name="__codelineno-8-52" href="#__codelineno-8-52"></a>baichuan_13b_base_qlora_medical_e1
<a id="__codelineno-8-53" name="__codelineno-8-53" href="#__codelineno-8-53"></a>baichuan_13b_base_qlora_moss_sft_all_e1
<a id="__codelineno-8-54" name="__codelineno-8-54" href="#__codelineno-8-54"></a>baichuan_13b_base_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-55" name="__codelineno-8-55" href="#__codelineno-8-55"></a>baichuan_13b_base_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-56" name="__codelineno-8-56" href="#__codelineno-8-56"></a>baichuan_13b_base_qlora_oasst1_512_e3
<a id="__codelineno-8-57" name="__codelineno-8-57" href="#__codelineno-8-57"></a>baichuan_13b_base_qlora_oasst1_e3
<a id="__codelineno-8-58" name="__codelineno-8-58" href="#__codelineno-8-58"></a>baichuan_13b_base_qlora_open_platypus_e3
<a id="__codelineno-8-59" name="__codelineno-8-59" href="#__codelineno-8-59"></a>baichuan_13b_base_qlora_openorca_e1
<a id="__codelineno-8-60" name="__codelineno-8-60" href="#__codelineno-8-60"></a>baichuan_13b_base_qlora_sql_e3
<a id="__codelineno-8-61" name="__codelineno-8-61" href="#__codelineno-8-61"></a>baichuan_13b_base_qlora_tiny_codes_e1
<a id="__codelineno-8-62" name="__codelineno-8-62" href="#__codelineno-8-62"></a>baichuan_13b_chat_qlora_alpaca_e3
<a id="__codelineno-8-63" name="__codelineno-8-63" href="#__codelineno-8-63"></a>baichuan_13b_chat_qlora_alpaca_enzh_e3
<a id="__codelineno-8-64" name="__codelineno-8-64" href="#__codelineno-8-64"></a>baichuan_13b_chat_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-65" name="__codelineno-8-65" href="#__codelineno-8-65"></a>baichuan_13b_chat_qlora_alpaca_zh_e3
<a id="__codelineno-8-66" name="__codelineno-8-66" href="#__codelineno-8-66"></a>baichuan_13b_chat_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-67" name="__codelineno-8-67" href="#__codelineno-8-67"></a>baichuan_13b_chat_qlora_code_alpaca_e3
<a id="__codelineno-8-68" name="__codelineno-8-68" href="#__codelineno-8-68"></a>baichuan_13b_chat_qlora_colorist_e5
<a id="__codelineno-8-69" name="__codelineno-8-69" href="#__codelineno-8-69"></a>baichuan_13b_chat_qlora_lawyer_e3
<a id="__codelineno-8-70" name="__codelineno-8-70" href="#__codelineno-8-70"></a>baichuan_13b_chat_qlora_medical_e1
<a id="__codelineno-8-71" name="__codelineno-8-71" href="#__codelineno-8-71"></a>baichuan_13b_chat_qlora_oasst1_512_e3
<a id="__codelineno-8-72" name="__codelineno-8-72" href="#__codelineno-8-72"></a>baichuan_13b_chat_qlora_oasst1_e3
<a id="__codelineno-8-73" name="__codelineno-8-73" href="#__codelineno-8-73"></a>baichuan_13b_chat_qlora_open_platypus_e3
<a id="__codelineno-8-74" name="__codelineno-8-74" href="#__codelineno-8-74"></a>baichuan_13b_chat_qlora_openorca_e1
<a id="__codelineno-8-75" name="__codelineno-8-75" href="#__codelineno-8-75"></a>baichuan_13b_chat_qlora_sql_e3
<a id="__codelineno-8-76" name="__codelineno-8-76" href="#__codelineno-8-76"></a>baichuan_13b_chat_qlora_tiny_codes_e1
<a id="__codelineno-8-77" name="__codelineno-8-77" href="#__codelineno-8-77"></a>baichuan_7b_qlora_alpaca_e3
<a id="__codelineno-8-78" name="__codelineno-8-78" href="#__codelineno-8-78"></a>baichuan_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-79" name="__codelineno-8-79" href="#__codelineno-8-79"></a>baichuan_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-80" name="__codelineno-8-80" href="#__codelineno-8-80"></a>baichuan_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-81" name="__codelineno-8-81" href="#__codelineno-8-81"></a>baichuan_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-82" name="__codelineno-8-82" href="#__codelineno-8-82"></a>baichuan_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-83" name="__codelineno-8-83" href="#__codelineno-8-83"></a>baichuan_7b_qlora_colorist_e5
<a id="__codelineno-8-84" name="__codelineno-8-84" href="#__codelineno-8-84"></a>baichuan_7b_qlora_lawyer_e3
<a id="__codelineno-8-85" name="__codelineno-8-85" href="#__codelineno-8-85"></a>baichuan_7b_qlora_medical_e1
<a id="__codelineno-8-86" name="__codelineno-8-86" href="#__codelineno-8-86"></a>baichuan_7b_qlora_moss_sft_all_e1
<a id="__codelineno-8-87" name="__codelineno-8-87" href="#__codelineno-8-87"></a>baichuan_7b_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-88" name="__codelineno-8-88" href="#__codelineno-8-88"></a>baichuan_7b_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-89" name="__codelineno-8-89" href="#__codelineno-8-89"></a>baichuan_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-90" name="__codelineno-8-90" href="#__codelineno-8-90"></a>baichuan_7b_qlora_oasst1_e3
<a id="__codelineno-8-91" name="__codelineno-8-91" href="#__codelineno-8-91"></a>baichuan_7b_qlora_open_platypus_e3
<a id="__codelineno-8-92" name="__codelineno-8-92" href="#__codelineno-8-92"></a>baichuan_7b_qlora_openorca_e1
<a id="__codelineno-8-93" name="__codelineno-8-93" href="#__codelineno-8-93"></a>baichuan_7b_qlora_sql_e3
<a id="__codelineno-8-94" name="__codelineno-8-94" href="#__codelineno-8-94"></a>baichuan_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-95" name="__codelineno-8-95" href="#__codelineno-8-95"></a>chatglm2_6b_qlora_alpaca_e3
<a id="__codelineno-8-96" name="__codelineno-8-96" href="#__codelineno-8-96"></a>chatglm2_6b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-97" name="__codelineno-8-97" href="#__codelineno-8-97"></a>chatglm2_6b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-98" name="__codelineno-8-98" href="#__codelineno-8-98"></a>chatglm2_6b_qlora_alpaca_zh_e3
<a id="__codelineno-8-99" name="__codelineno-8-99" href="#__codelineno-8-99"></a>chatglm2_6b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-100" name="__codelineno-8-100" href="#__codelineno-8-100"></a>chatglm2_6b_qlora_code_alpaca_e3
<a id="__codelineno-8-101" name="__codelineno-8-101" href="#__codelineno-8-101"></a>chatglm2_6b_qlora_colorist_e5
<a id="__codelineno-8-102" name="__codelineno-8-102" href="#__codelineno-8-102"></a>chatglm2_6b_qlora_lawyer_e3
<a id="__codelineno-8-103" name="__codelineno-8-103" href="#__codelineno-8-103"></a>chatglm2_6b_qlora_medical_e1
<a id="__codelineno-8-104" name="__codelineno-8-104" href="#__codelineno-8-104"></a>chatglm2_6b_qlora_oasst1_512_e3
<a id="__codelineno-8-105" name="__codelineno-8-105" href="#__codelineno-8-105"></a>chatglm2_6b_qlora_oasst1_e3
<a id="__codelineno-8-106" name="__codelineno-8-106" href="#__codelineno-8-106"></a>chatglm2_6b_qlora_open_platypus_e3
<a id="__codelineno-8-107" name="__codelineno-8-107" href="#__codelineno-8-107"></a>chatglm2_6b_qlora_openorca_e1
<a id="__codelineno-8-108" name="__codelineno-8-108" href="#__codelineno-8-108"></a>chatglm2_6b_qlora_sql_e3
<a id="__codelineno-8-109" name="__codelineno-8-109" href="#__codelineno-8-109"></a>chatglm2_6b_qlora_tiny_codes_e1
<a id="__codelineno-8-110" name="__codelineno-8-110" href="#__codelineno-8-110"></a>chatglm3_6b_base_qlora_alpaca_e3
<a id="__codelineno-8-111" name="__codelineno-8-111" href="#__codelineno-8-111"></a>chatglm3_6b_base_qlora_alpaca_enzh_e3
<a id="__codelineno-8-112" name="__codelineno-8-112" href="#__codelineno-8-112"></a>chatglm3_6b_base_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-113" name="__codelineno-8-113" href="#__codelineno-8-113"></a>chatglm3_6b_base_qlora_alpaca_zh_e3
<a id="__codelineno-8-114" name="__codelineno-8-114" href="#__codelineno-8-114"></a>chatglm3_6b_base_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-115" name="__codelineno-8-115" href="#__codelineno-8-115"></a>chatglm3_6b_base_qlora_code_alpaca_e3
<a id="__codelineno-8-116" name="__codelineno-8-116" href="#__codelineno-8-116"></a>chatglm3_6b_base_qlora_colorist_e5
<a id="__codelineno-8-117" name="__codelineno-8-117" href="#__codelineno-8-117"></a>chatglm3_6b_base_qlora_lawyer_e3
<a id="__codelineno-8-118" name="__codelineno-8-118" href="#__codelineno-8-118"></a>chatglm3_6b_base_qlora_medical_e1
<a id="__codelineno-8-119" name="__codelineno-8-119" href="#__codelineno-8-119"></a>chatglm3_6b_base_qlora_oasst1_512_e3
<a id="__codelineno-8-120" name="__codelineno-8-120" href="#__codelineno-8-120"></a>chatglm3_6b_base_qlora_oasst1_e3
<a id="__codelineno-8-121" name="__codelineno-8-121" href="#__codelineno-8-121"></a>chatglm3_6b_base_qlora_open_platypus_e3
<a id="__codelineno-8-122" name="__codelineno-8-122" href="#__codelineno-8-122"></a>chatglm3_6b_base_qlora_openorca_e1
<a id="__codelineno-8-123" name="__codelineno-8-123" href="#__codelineno-8-123"></a>chatglm3_6b_base_qlora_sql_e3
<a id="__codelineno-8-124" name="__codelineno-8-124" href="#__codelineno-8-124"></a>chatglm3_6b_base_qlora_tiny_codes_e1
<a id="__codelineno-8-125" name="__codelineno-8-125" href="#__codelineno-8-125"></a>chatglm3_6b_qlora_alpaca_e3
<a id="__codelineno-8-126" name="__codelineno-8-126" href="#__codelineno-8-126"></a>chatglm3_6b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-127" name="__codelineno-8-127" href="#__codelineno-8-127"></a>chatglm3_6b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-128" name="__codelineno-8-128" href="#__codelineno-8-128"></a>chatglm3_6b_qlora_alpaca_zh_e3
<a id="__codelineno-8-129" name="__codelineno-8-129" href="#__codelineno-8-129"></a>chatglm3_6b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-130" name="__codelineno-8-130" href="#__codelineno-8-130"></a>chatglm3_6b_qlora_code_alpaca_e3
<a id="__codelineno-8-131" name="__codelineno-8-131" href="#__codelineno-8-131"></a>chatglm3_6b_qlora_colorist_e5
<a id="__codelineno-8-132" name="__codelineno-8-132" href="#__codelineno-8-132"></a>chatglm3_6b_qlora_lawyer_e3
<a id="__codelineno-8-133" name="__codelineno-8-133" href="#__codelineno-8-133"></a>chatglm3_6b_qlora_medical_e1
<a id="__codelineno-8-134" name="__codelineno-8-134" href="#__codelineno-8-134"></a>chatglm3_6b_qlora_oasst1_512_e3
<a id="__codelineno-8-135" name="__codelineno-8-135" href="#__codelineno-8-135"></a>chatglm3_6b_qlora_oasst1_e3
<a id="__codelineno-8-136" name="__codelineno-8-136" href="#__codelineno-8-136"></a>chatglm3_6b_qlora_open_platypus_e3
<a id="__codelineno-8-137" name="__codelineno-8-137" href="#__codelineno-8-137"></a>chatglm3_6b_qlora_openorca_e1
<a id="__codelineno-8-138" name="__codelineno-8-138" href="#__codelineno-8-138"></a>chatglm3_6b_qlora_sql_e3
<a id="__codelineno-8-139" name="__codelineno-8-139" href="#__codelineno-8-139"></a>chatglm3_6b_qlora_tiny_codes_e1
<a id="__codelineno-8-140" name="__codelineno-8-140" href="#__codelineno-8-140"></a>deepspeed_zero1
<a id="__codelineno-8-141" name="__codelineno-8-141" href="#__codelineno-8-141"></a>deepspeed_zero2
<a id="__codelineno-8-142" name="__codelineno-8-142" href="#__codelineno-8-142"></a>deepspeed_zero2_offload
<a id="__codelineno-8-143" name="__codelineno-8-143" href="#__codelineno-8-143"></a>deepspeed_zero3
<a id="__codelineno-8-144" name="__codelineno-8-144" href="#__codelineno-8-144"></a>deepspeed_zero3_offload
<a id="__codelineno-8-145" name="__codelineno-8-145" href="#__codelineno-8-145"></a>internlm_20b_qlora_alpaca_e3
<a id="__codelineno-8-146" name="__codelineno-8-146" href="#__codelineno-8-146"></a>internlm_20b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-147" name="__codelineno-8-147" href="#__codelineno-8-147"></a>internlm_20b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-148" name="__codelineno-8-148" href="#__codelineno-8-148"></a>internlm_20b_qlora_alpaca_zh_e3
<a id="__codelineno-8-149" name="__codelineno-8-149" href="#__codelineno-8-149"></a>internlm_20b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-150" name="__codelineno-8-150" href="#__codelineno-8-150"></a>internlm_20b_qlora_code_alpaca_e3
<a id="__codelineno-8-151" name="__codelineno-8-151" href="#__codelineno-8-151"></a>internlm_20b_qlora_colorist_e5
<a id="__codelineno-8-152" name="__codelineno-8-152" href="#__codelineno-8-152"></a>internlm_20b_qlora_lawyer_e3
<a id="__codelineno-8-153" name="__codelineno-8-153" href="#__codelineno-8-153"></a>internlm_20b_qlora_msagent_react_e3_gpu8
<a id="__codelineno-8-154" name="__codelineno-8-154" href="#__codelineno-8-154"></a>internlm_20b_qlora_oasst1_512_e3
<a id="__codelineno-8-155" name="__codelineno-8-155" href="#__codelineno-8-155"></a>internlm_20b_qlora_oasst1_e3
<a id="__codelineno-8-156" name="__codelineno-8-156" href="#__codelineno-8-156"></a>internlm_20b_qlora_open_platypus_e3
<a id="__codelineno-8-157" name="__codelineno-8-157" href="#__codelineno-8-157"></a>internlm_20b_qlora_sql_e3
<a id="__codelineno-8-158" name="__codelineno-8-158" href="#__codelineno-8-158"></a>internlm_7b_full_alpaca_e3
<a id="__codelineno-8-159" name="__codelineno-8-159" href="#__codelineno-8-159"></a>internlm_7b_full_alpaca_enzh_e3
<a id="__codelineno-8-160" name="__codelineno-8-160" href="#__codelineno-8-160"></a>internlm_7b_full_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-161" name="__codelineno-8-161" href="#__codelineno-8-161"></a>internlm_7b_full_alpaca_zh_e3
<a id="__codelineno-8-162" name="__codelineno-8-162" href="#__codelineno-8-162"></a>internlm_7b_full_oasst1_e3
<a id="__codelineno-8-163" name="__codelineno-8-163" href="#__codelineno-8-163"></a>internlm_7b_qlora_alpaca_e3
<a id="__codelineno-8-164" name="__codelineno-8-164" href="#__codelineno-8-164"></a>internlm_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-165" name="__codelineno-8-165" href="#__codelineno-8-165"></a>internlm_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-166" name="__codelineno-8-166" href="#__codelineno-8-166"></a>internlm_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-167" name="__codelineno-8-167" href="#__codelineno-8-167"></a>internlm_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-168" name="__codelineno-8-168" href="#__codelineno-8-168"></a>internlm_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-169" name="__codelineno-8-169" href="#__codelineno-8-169"></a>internlm_7b_qlora_colorist_e5
<a id="__codelineno-8-170" name="__codelineno-8-170" href="#__codelineno-8-170"></a>internlm_7b_qlora_lawyer_e3
<a id="__codelineno-8-171" name="__codelineno-8-171" href="#__codelineno-8-171"></a>internlm_7b_qlora_medical_e1
<a id="__codelineno-8-172" name="__codelineno-8-172" href="#__codelineno-8-172"></a>internlm_7b_qlora_moss_sft_all_e1
<a id="__codelineno-8-173" name="__codelineno-8-173" href="#__codelineno-8-173"></a>internlm_7b_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-174" name="__codelineno-8-174" href="#__codelineno-8-174"></a>internlm_7b_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-175" name="__codelineno-8-175" href="#__codelineno-8-175"></a>internlm_7b_qlora_msagent_react_e3_gpu8
<a id="__codelineno-8-176" name="__codelineno-8-176" href="#__codelineno-8-176"></a>internlm_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-177" name="__codelineno-8-177" href="#__codelineno-8-177"></a>internlm_7b_qlora_oasst1_e3
<a id="__codelineno-8-178" name="__codelineno-8-178" href="#__codelineno-8-178"></a>internlm_7b_qlora_oasst1_e3_hf
<a id="__codelineno-8-179" name="__codelineno-8-179" href="#__codelineno-8-179"></a>internlm_7b_qlora_oasst1_mmlu_e3
<a id="__codelineno-8-180" name="__codelineno-8-180" href="#__codelineno-8-180"></a>internlm_7b_qlora_open_platypus_e3
<a id="__codelineno-8-181" name="__codelineno-8-181" href="#__codelineno-8-181"></a>internlm_7b_qlora_openorca_e1
<a id="__codelineno-8-182" name="__codelineno-8-182" href="#__codelineno-8-182"></a>internlm_7b_qlora_sql_e3
<a id="__codelineno-8-183" name="__codelineno-8-183" href="#__codelineno-8-183"></a>internlm_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-184" name="__codelineno-8-184" href="#__codelineno-8-184"></a>internlm_chat_20b_qlora_alpaca_e3
<a id="__codelineno-8-185" name="__codelineno-8-185" href="#__codelineno-8-185"></a>internlm_chat_20b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-186" name="__codelineno-8-186" href="#__codelineno-8-186"></a>internlm_chat_20b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-187" name="__codelineno-8-187" href="#__codelineno-8-187"></a>internlm_chat_20b_qlora_alpaca_zh_e3
<a id="__codelineno-8-188" name="__codelineno-8-188" href="#__codelineno-8-188"></a>internlm_chat_20b_qlora_code_alpaca_e3
<a id="__codelineno-8-189" name="__codelineno-8-189" href="#__codelineno-8-189"></a>internlm_chat_20b_qlora_lawyer_e3
<a id="__codelineno-8-190" name="__codelineno-8-190" href="#__codelineno-8-190"></a>internlm_chat_20b_qlora_oasst1_512_e3
<a id="__codelineno-8-191" name="__codelineno-8-191" href="#__codelineno-8-191"></a>internlm_chat_20b_qlora_oasst1_e3
<a id="__codelineno-8-192" name="__codelineno-8-192" href="#__codelineno-8-192"></a>internlm_chat_20b_qlora_open_platypus_e3
<a id="__codelineno-8-193" name="__codelineno-8-193" href="#__codelineno-8-193"></a>internlm_chat_7b_qlora_alpaca_e3
<a id="__codelineno-8-194" name="__codelineno-8-194" href="#__codelineno-8-194"></a>internlm_chat_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-195" name="__codelineno-8-195" href="#__codelineno-8-195"></a>internlm_chat_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-196" name="__codelineno-8-196" href="#__codelineno-8-196"></a>internlm_chat_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-197" name="__codelineno-8-197" href="#__codelineno-8-197"></a>internlm_chat_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-198" name="__codelineno-8-198" href="#__codelineno-8-198"></a>internlm_chat_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-199" name="__codelineno-8-199" href="#__codelineno-8-199"></a>internlm_chat_7b_qlora_colorist_e5
<a id="__codelineno-8-200" name="__codelineno-8-200" href="#__codelineno-8-200"></a>internlm_chat_7b_qlora_lawyer_e3
<a id="__codelineno-8-201" name="__codelineno-8-201" href="#__codelineno-8-201"></a>internlm_chat_7b_qlora_medical_e1
<a id="__codelineno-8-202" name="__codelineno-8-202" href="#__codelineno-8-202"></a>internlm_chat_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-203" name="__codelineno-8-203" href="#__codelineno-8-203"></a>internlm_chat_7b_qlora_oasst1_e3
<a id="__codelineno-8-204" name="__codelineno-8-204" href="#__codelineno-8-204"></a>internlm_chat_7b_qlora_open_platypus_e3
<a id="__codelineno-8-205" name="__codelineno-8-205" href="#__codelineno-8-205"></a>internlm_chat_7b_qlora_openorca_e1
<a id="__codelineno-8-206" name="__codelineno-8-206" href="#__codelineno-8-206"></a>internlm_chat_7b_qlora_sql_e3
<a id="__codelineno-8-207" name="__codelineno-8-207" href="#__codelineno-8-207"></a>internlm_chat_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-208" name="__codelineno-8-208" href="#__codelineno-8-208"></a>llama2_70b_int8_lora_open_platypus_e1
<a id="__codelineno-8-209" name="__codelineno-8-209" href="#__codelineno-8-209"></a>llama2_70b_int8_lora_open_platypus_e1_hf
<a id="__codelineno-8-210" name="__codelineno-8-210" href="#__codelineno-8-210"></a>llama2_70b_qlora_open_platypus_e1
<a id="__codelineno-8-211" name="__codelineno-8-211" href="#__codelineno-8-211"></a>llama2_70b_qlora_open_platypus_e1_hf
<a id="__codelineno-8-212" name="__codelineno-8-212" href="#__codelineno-8-212"></a>llama2_7b_chat_qlora_alpaca_e3
<a id="__codelineno-8-213" name="__codelineno-8-213" href="#__codelineno-8-213"></a>llama2_7b_chat_qlora_alpaca_enzh_e3
<a id="__codelineno-8-214" name="__codelineno-8-214" href="#__codelineno-8-214"></a>llama2_7b_chat_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-215" name="__codelineno-8-215" href="#__codelineno-8-215"></a>llama2_7b_chat_qlora_alpaca_zh_e3
<a id="__codelineno-8-216" name="__codelineno-8-216" href="#__codelineno-8-216"></a>llama2_7b_chat_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-217" name="__codelineno-8-217" href="#__codelineno-8-217"></a>llama2_7b_chat_qlora_code_alpaca_e3
<a id="__codelineno-8-218" name="__codelineno-8-218" href="#__codelineno-8-218"></a>llama2_7b_chat_qlora_colorist_e5
<a id="__codelineno-8-219" name="__codelineno-8-219" href="#__codelineno-8-219"></a>llama2_7b_chat_qlora_lawyer_e3
<a id="__codelineno-8-220" name="__codelineno-8-220" href="#__codelineno-8-220"></a>llama2_7b_chat_qlora_medical_e1
<a id="__codelineno-8-221" name="__codelineno-8-221" href="#__codelineno-8-221"></a>llama2_7b_chat_qlora_oasst1_512_e3
<a id="__codelineno-8-222" name="__codelineno-8-222" href="#__codelineno-8-222"></a>llama2_7b_chat_qlora_oasst1_e3
<a id="__codelineno-8-223" name="__codelineno-8-223" href="#__codelineno-8-223"></a>llama2_7b_chat_qlora_open_platypus_e3
<a id="__codelineno-8-224" name="__codelineno-8-224" href="#__codelineno-8-224"></a>llama2_7b_chat_qlora_openorca_e1
<a id="__codelineno-8-225" name="__codelineno-8-225" href="#__codelineno-8-225"></a>llama2_7b_chat_qlora_sql_e3
<a id="__codelineno-8-226" name="__codelineno-8-226" href="#__codelineno-8-226"></a>llama2_7b_chat_qlora_tiny_codes_e1
<a id="__codelineno-8-227" name="__codelineno-8-227" href="#__codelineno-8-227"></a>llama2_7b_full_wizardlm_e1
<a id="__codelineno-8-228" name="__codelineno-8-228" href="#__codelineno-8-228"></a>llama2_7b_qlora_alpaca_e3
<a id="__codelineno-8-229" name="__codelineno-8-229" href="#__codelineno-8-229"></a>llama2_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-230" name="__codelineno-8-230" href="#__codelineno-8-230"></a>llama2_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-231" name="__codelineno-8-231" href="#__codelineno-8-231"></a>llama2_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-232" name="__codelineno-8-232" href="#__codelineno-8-232"></a>llama2_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-233" name="__codelineno-8-233" href="#__codelineno-8-233"></a>llama2_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-234" name="__codelineno-8-234" href="#__codelineno-8-234"></a>llama2_7b_qlora_colorist_e5
<a id="__codelineno-8-235" name="__codelineno-8-235" href="#__codelineno-8-235"></a>llama2_7b_qlora_lawyer_e3
<a id="__codelineno-8-236" name="__codelineno-8-236" href="#__codelineno-8-236"></a>llama2_7b_qlora_medical_e1
<a id="__codelineno-8-237" name="__codelineno-8-237" href="#__codelineno-8-237"></a>llama2_7b_qlora_moss_sft_all_e1
<a id="__codelineno-8-238" name="__codelineno-8-238" href="#__codelineno-8-238"></a>llama2_7b_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-239" name="__codelineno-8-239" href="#__codelineno-8-239"></a>llama2_7b_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-240" name="__codelineno-8-240" href="#__codelineno-8-240"></a>llama2_7b_qlora_msagent_react_e3_gpu8
<a id="__codelineno-8-241" name="__codelineno-8-241" href="#__codelineno-8-241"></a>llama2_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-242" name="__codelineno-8-242" href="#__codelineno-8-242"></a>llama2_7b_qlora_oasst1_e3
<a id="__codelineno-8-243" name="__codelineno-8-243" href="#__codelineno-8-243"></a>llama2_7b_qlora_open_platypus_e3
<a id="__codelineno-8-244" name="__codelineno-8-244" href="#__codelineno-8-244"></a>llama2_7b_qlora_openorca_e1
<a id="__codelineno-8-245" name="__codelineno-8-245" href="#__codelineno-8-245"></a>llama2_7b_qlora_sql_e3
<a id="__codelineno-8-246" name="__codelineno-8-246" href="#__codelineno-8-246"></a>llama2_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-247" name="__codelineno-8-247" href="#__codelineno-8-247"></a>llama_7b_qlora_alpaca_e3
<a id="__codelineno-8-248" name="__codelineno-8-248" href="#__codelineno-8-248"></a>llama_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-249" name="__codelineno-8-249" href="#__codelineno-8-249"></a>llama_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-250" name="__codelineno-8-250" href="#__codelineno-8-250"></a>llama_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-251" name="__codelineno-8-251" href="#__codelineno-8-251"></a>llama_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-252" name="__codelineno-8-252" href="#__codelineno-8-252"></a>llama_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-253" name="__codelineno-8-253" href="#__codelineno-8-253"></a>llama_7b_qlora_colorist_e5
<a id="__codelineno-8-254" name="__codelineno-8-254" href="#__codelineno-8-254"></a>llama_7b_qlora_lawyer_e3
<a id="__codelineno-8-255" name="__codelineno-8-255" href="#__codelineno-8-255"></a>llama_7b_qlora_medical_e1
<a id="__codelineno-8-256" name="__codelineno-8-256" href="#__codelineno-8-256"></a>llama_7b_qlora_moss_sft_all_e1
<a id="__codelineno-8-257" name="__codelineno-8-257" href="#__codelineno-8-257"></a>llama_7b_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-258" name="__codelineno-8-258" href="#__codelineno-8-258"></a>llama_7b_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-259" name="__codelineno-8-259" href="#__codelineno-8-259"></a>llama_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-260" name="__codelineno-8-260" href="#__codelineno-8-260"></a>llama_7b_qlora_oasst1_e3
<a id="__codelineno-8-261" name="__codelineno-8-261" href="#__codelineno-8-261"></a>llama_7b_qlora_open_platypus_e3
<a id="__codelineno-8-262" name="__codelineno-8-262" href="#__codelineno-8-262"></a>llama_7b_qlora_openorca_e1
<a id="__codelineno-8-263" name="__codelineno-8-263" href="#__codelineno-8-263"></a>llama_7b_qlora_sql_e3
<a id="__codelineno-8-264" name="__codelineno-8-264" href="#__codelineno-8-264"></a>llama_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-265" name="__codelineno-8-265" href="#__codelineno-8-265"></a>mistral_7b_qlora_skypile_pretrain_e1
<a id="__codelineno-8-266" name="__codelineno-8-266" href="#__codelineno-8-266"></a>qwen_7b_chat_qlora_alpaca_e3
<a id="__codelineno-8-267" name="__codelineno-8-267" href="#__codelineno-8-267"></a>qwen_7b_chat_qlora_alpaca_enzh_e3
<a id="__codelineno-8-268" name="__codelineno-8-268" href="#__codelineno-8-268"></a>qwen_7b_chat_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-269" name="__codelineno-8-269" href="#__codelineno-8-269"></a>qwen_7b_chat_qlora_alpaca_zh_e3
<a id="__codelineno-8-270" name="__codelineno-8-270" href="#__codelineno-8-270"></a>qwen_7b_chat_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-271" name="__codelineno-8-271" href="#__codelineno-8-271"></a>qwen_7b_chat_qlora_code_alpaca_e3
<a id="__codelineno-8-272" name="__codelineno-8-272" href="#__codelineno-8-272"></a>qwen_7b_chat_qlora_colorist_e5
<a id="__codelineno-8-273" name="__codelineno-8-273" href="#__codelineno-8-273"></a>qwen_7b_chat_qlora_lawyer_e3
<a id="__codelineno-8-274" name="__codelineno-8-274" href="#__codelineno-8-274"></a>qwen_7b_chat_qlora_medical_e1
<a id="__codelineno-8-275" name="__codelineno-8-275" href="#__codelineno-8-275"></a>qwen_7b_chat_qlora_oasst1_512_e3
<a id="__codelineno-8-276" name="__codelineno-8-276" href="#__codelineno-8-276"></a>qwen_7b_chat_qlora_oasst1_e3
<a id="__codelineno-8-277" name="__codelineno-8-277" href="#__codelineno-8-277"></a>qwen_7b_chat_qlora_open_platypus_e3
<a id="__codelineno-8-278" name="__codelineno-8-278" href="#__codelineno-8-278"></a>qwen_7b_chat_qlora_openorca_e1
<a id="__codelineno-8-279" name="__codelineno-8-279" href="#__codelineno-8-279"></a>qwen_7b_chat_qlora_sql_e3
<a id="__codelineno-8-280" name="__codelineno-8-280" href="#__codelineno-8-280"></a>qwen_7b_chat_qlora_tiny_codes_e1
<a id="__codelineno-8-281" name="__codelineno-8-281" href="#__codelineno-8-281"></a>qwen_7b_qlora_alpaca_e3
<a id="__codelineno-8-282" name="__codelineno-8-282" href="#__codelineno-8-282"></a>qwen_7b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-283" name="__codelineno-8-283" href="#__codelineno-8-283"></a>qwen_7b_qlora_alpaca_enzh_oasst1_e3
<a id="__codelineno-8-284" name="__codelineno-8-284" href="#__codelineno-8-284"></a>qwen_7b_qlora_alpaca_zh_e3
<a id="__codelineno-8-285" name="__codelineno-8-285" href="#__codelineno-8-285"></a>qwen_7b_qlora_arxiv_gentitle_e3
<a id="__codelineno-8-286" name="__codelineno-8-286" href="#__codelineno-8-286"></a>qwen_7b_qlora_code_alpaca_e3
<a id="__codelineno-8-287" name="__codelineno-8-287" href="#__codelineno-8-287"></a>qwen_7b_qlora_colorist_e5
<a id="__codelineno-8-288" name="__codelineno-8-288" href="#__codelineno-8-288"></a>qwen_7b_qlora_lawyer_e3
<a id="__codelineno-8-289" name="__codelineno-8-289" href="#__codelineno-8-289"></a>qwen_7b_qlora_medical_e1
<a id="__codelineno-8-290" name="__codelineno-8-290" href="#__codelineno-8-290"></a>qwen_7b_qlora_moss_sft_all_e1
<a id="__codelineno-8-291" name="__codelineno-8-291" href="#__codelineno-8-291"></a>qwen_7b_qlora_moss_sft_all_e2_gpu8
<a id="__codelineno-8-292" name="__codelineno-8-292" href="#__codelineno-8-292"></a>qwen_7b_qlora_moss_sft_plugins_e1
<a id="__codelineno-8-293" name="__codelineno-8-293" href="#__codelineno-8-293"></a>qwen_7b_qlora_oasst1_512_e3
<a id="__codelineno-8-294" name="__codelineno-8-294" href="#__codelineno-8-294"></a>qwen_7b_qlora_oasst1_e3
<a id="__codelineno-8-295" name="__codelineno-8-295" href="#__codelineno-8-295"></a>qwen_7b_qlora_open_platypus_e3
<a id="__codelineno-8-296" name="__codelineno-8-296" href="#__codelineno-8-296"></a>qwen_7b_qlora_openorca_e1
<a id="__codelineno-8-297" name="__codelineno-8-297" href="#__codelineno-8-297"></a>qwen_7b_qlora_sql_e3
<a id="__codelineno-8-298" name="__codelineno-8-298" href="#__codelineno-8-298"></a>qwen_7b_qlora_tiny_codes_e1
<a id="__codelineno-8-299" name="__codelineno-8-299" href="#__codelineno-8-299"></a>starcoder_qlora_stack_exchange_example
<a id="__codelineno-8-300" name="__codelineno-8-300" href="#__codelineno-8-300"></a>yi_34b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-301" name="__codelineno-8-301" href="#__codelineno-8-301"></a>yi_6b_qlora_alpaca_enzh_e3
<a id="__codelineno-8-302" name="__codelineno-8-302" href="#__codelineno-8-302"></a><span class="nv">zephyr_7b_beta_qlora_alpaca_e3</span>
<a id="__codelineno-8-303" name="__codelineno-8-303" href="#__codelineno-8-303"></a><span class="o">=============================================================</span>
</code></pre></div>
</details>

<ul>
<li>拷贝一个配置文件到当前目录：
<div class="highlight"><pre><span></span><code><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="nb">cd</span><span class="w"> </span>~/ft-oasst1
<a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a>xtuner<span class="w"> </span>copy-cfg<span class="w"> </span>internlm_chat_7b_qlora_oasst1_e3<span class="w"> </span>.
</code></pre></div>
<img alt="alt text" src="../image-101.png" /></li>
</ul>
<h5 id="2222">2.2.2.2 模型设置</h5>
<ul>
<li>设置软链接</li>
</ul>
<p><div class="highlight"><pre><span></span><code><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>ln<span class="w"> </span>-s<span class="w"> </span>/share/temp/model_repos/internlm-chat-7b<span class="w"> </span>~/ft-oasst1/
</code></pre></div>
<img alt="alt text" src="../image-102.png" /></p>
<h5 id="2223">2.2.2.3 数据集下载</h5>
<p><a href="https://huggingface.co/datasets/timdettmers/openassistant-guanaco/tree/main">数据集Huggingface地址</a></p>
<ul>
<li>从开发机share地址拷贝到ft-oasst1文件夹下
<div class="highlight"><pre><span></span><code><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="nb">cd</span><span class="w"> </span>~/ft-oasst1
<a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a><span class="c1"># ...-guanaco 后面有个空格和英文句号啊</span>
<a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>cp<span class="w"> </span>-r<span class="w"> </span>/root/share/temp/datasets/openassistant-guanaco<span class="w"> </span>.
</code></pre></div></li>
</ul>
<p><img alt="alt text" src="../image-103.png" /></p>
<h5 id="2224">2.2.2.4 修改配置文件</h5>
<ul>
<li>修改internlm_chat_7b_qlora_oasst1_e3_copy.py配置文件模型及数据为本地模型及数据</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="c1"># pretrained_model_name_or_path = &#39;internlm/internlm-chat-7b&#39;</span>
<a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="n">pretrained_model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;internlm/internlm-chat-7b&#39;</span>
<a id="__codelineno-12-3" name="__codelineno-12-3" href="#__codelineno-12-3"></a>
<a id="__codelineno-12-4" name="__codelineno-12-4" href="#__codelineno-12-4"></a><span class="c1"># Data</span>
<a id="__codelineno-12-5" name="__codelineno-12-5" href="#__codelineno-12-5"></a><span class="c1"># data_path = &#39;timdettmers/openassistant-guanaco&#39;</span>
<a id="__codelineno-12-6" name="__codelineno-12-6" href="#__codelineno-12-6"></a><span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./openassistant-guanaco&#39;</span>
</code></pre></div>
<p><img alt="alt text" src="../image-104.png" /></p>
<p>修改后的配置文件internlm_chat_7b_qlora_oasst1_e3_copy.py</p>
<details>
<summary>internlm_chat_7b_qlora_oasst1_e3_copy.py</summary>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-13-1">  1</a></span>
<span class="normal"><a href="#__codelineno-13-2">  2</a></span>
<span class="normal"><a href="#__codelineno-13-3">  3</a></span>
<span class="normal"><a href="#__codelineno-13-4">  4</a></span>
<span class="normal"><a href="#__codelineno-13-5">  5</a></span>
<span class="normal"><a href="#__codelineno-13-6">  6</a></span>
<span class="normal"><a href="#__codelineno-13-7">  7</a></span>
<span class="normal"><a href="#__codelineno-13-8">  8</a></span>
<span class="normal"><a href="#__codelineno-13-9">  9</a></span>
<span class="normal"><a href="#__codelineno-13-10"> 10</a></span>
<span class="normal"><a href="#__codelineno-13-11"> 11</a></span>
<span class="normal"><a href="#__codelineno-13-12"> 12</a></span>
<span class="normal"><a href="#__codelineno-13-13"> 13</a></span>
<span class="normal"><a href="#__codelineno-13-14"> 14</a></span>
<span class="normal"><a href="#__codelineno-13-15"> 15</a></span>
<span class="normal"><a href="#__codelineno-13-16"> 16</a></span>
<span class="normal"><a href="#__codelineno-13-17"> 17</a></span>
<span class="normal"><a href="#__codelineno-13-18"> 18</a></span>
<span class="normal"><a href="#__codelineno-13-19"> 19</a></span>
<span class="normal"><a href="#__codelineno-13-20"> 20</a></span>
<span class="normal"><a href="#__codelineno-13-21"> 21</a></span>
<span class="normal"><a href="#__codelineno-13-22"> 22</a></span>
<span class="normal"><a href="#__codelineno-13-23"> 23</a></span>
<span class="normal"><a href="#__codelineno-13-24"> 24</a></span>
<span class="normal"><a href="#__codelineno-13-25"> 25</a></span>
<span class="normal"><a href="#__codelineno-13-26"> 26</a></span>
<span class="normal"><a href="#__codelineno-13-27"> 27</a></span>
<span class="normal"><a href="#__codelineno-13-28"> 28</a></span>
<span class="normal"><a href="#__codelineno-13-29"> 29</a></span>
<span class="normal"><a href="#__codelineno-13-30"> 30</a></span>
<span class="normal"><a href="#__codelineno-13-31"> 31</a></span>
<span class="normal"><a href="#__codelineno-13-32"> 32</a></span>
<span class="normal"><a href="#__codelineno-13-33"> 33</a></span>
<span class="normal"><a href="#__codelineno-13-34"> 34</a></span>
<span class="normal"><a href="#__codelineno-13-35"> 35</a></span>
<span class="normal"><a href="#__codelineno-13-36"> 36</a></span>
<span class="normal"><a href="#__codelineno-13-37"> 37</a></span>
<span class="normal"><a href="#__codelineno-13-38"> 38</a></span>
<span class="normal"><a href="#__codelineno-13-39"> 39</a></span>
<span class="normal"><a href="#__codelineno-13-40"> 40</a></span>
<span class="normal"><a href="#__codelineno-13-41"> 41</a></span>
<span class="normal"><a href="#__codelineno-13-42"> 42</a></span>
<span class="normal"><a href="#__codelineno-13-43"> 43</a></span>
<span class="normal"><a href="#__codelineno-13-44"> 44</a></span>
<span class="normal"><a href="#__codelineno-13-45"> 45</a></span>
<span class="normal"><a href="#__codelineno-13-46"> 46</a></span>
<span class="normal"><a href="#__codelineno-13-47"> 47</a></span>
<span class="normal"><a href="#__codelineno-13-48"> 48</a></span>
<span class="normal"><a href="#__codelineno-13-49"> 49</a></span>
<span class="normal"><a href="#__codelineno-13-50"> 50</a></span>
<span class="normal"><a href="#__codelineno-13-51"> 51</a></span>
<span class="normal"><a href="#__codelineno-13-52"> 52</a></span>
<span class="normal"><a href="#__codelineno-13-53"> 53</a></span>
<span class="normal"><a href="#__codelineno-13-54"> 54</a></span>
<span class="normal"><a href="#__codelineno-13-55"> 55</a></span>
<span class="normal"><a href="#__codelineno-13-56"> 56</a></span>
<span class="normal"><a href="#__codelineno-13-57"> 57</a></span>
<span class="normal"><a href="#__codelineno-13-58"> 58</a></span>
<span class="normal"><a href="#__codelineno-13-59"> 59</a></span>
<span class="normal"><a href="#__codelineno-13-60"> 60</a></span>
<span class="normal"><a href="#__codelineno-13-61"> 61</a></span>
<span class="normal"><a href="#__codelineno-13-62"> 62</a></span>
<span class="normal"><a href="#__codelineno-13-63"> 63</a></span>
<span class="normal"><a href="#__codelineno-13-64"> 64</a></span>
<span class="normal"><a href="#__codelineno-13-65"> 65</a></span>
<span class="normal"><a href="#__codelineno-13-66"> 66</a></span>
<span class="normal"><a href="#__codelineno-13-67"> 67</a></span>
<span class="normal"><a href="#__codelineno-13-68"> 68</a></span>
<span class="normal"><a href="#__codelineno-13-69"> 69</a></span>
<span class="normal"><a href="#__codelineno-13-70"> 70</a></span>
<span class="normal"><a href="#__codelineno-13-71"> 71</a></span>
<span class="normal"><a href="#__codelineno-13-72"> 72</a></span>
<span class="normal"><a href="#__codelineno-13-73"> 73</a></span>
<span class="normal"><a href="#__codelineno-13-74"> 74</a></span>
<span class="normal"><a href="#__codelineno-13-75"> 75</a></span>
<span class="normal"><a href="#__codelineno-13-76"> 76</a></span>
<span class="normal"><a href="#__codelineno-13-77"> 77</a></span>
<span class="normal"><a href="#__codelineno-13-78"> 78</a></span>
<span class="normal"><a href="#__codelineno-13-79"> 79</a></span>
<span class="normal"><a href="#__codelineno-13-80"> 80</a></span>
<span class="normal"><a href="#__codelineno-13-81"> 81</a></span>
<span class="normal"><a href="#__codelineno-13-82"> 82</a></span>
<span class="normal"><a href="#__codelineno-13-83"> 83</a></span>
<span class="normal"><a href="#__codelineno-13-84"> 84</a></span>
<span class="normal"><a href="#__codelineno-13-85"> 85</a></span>
<span class="normal"><a href="#__codelineno-13-86"> 86</a></span>
<span class="normal"><a href="#__codelineno-13-87"> 87</a></span>
<span class="normal"><a href="#__codelineno-13-88"> 88</a></span>
<span class="normal"><a href="#__codelineno-13-89"> 89</a></span>
<span class="normal"><a href="#__codelineno-13-90"> 90</a></span>
<span class="normal"><a href="#__codelineno-13-91"> 91</a></span>
<span class="normal"><a href="#__codelineno-13-92"> 92</a></span>
<span class="normal"><a href="#__codelineno-13-93"> 93</a></span>
<span class="normal"><a href="#__codelineno-13-94"> 94</a></span>
<span class="normal"><a href="#__codelineno-13-95"> 95</a></span>
<span class="normal"><a href="#__codelineno-13-96"> 96</a></span>
<span class="normal"><a href="#__codelineno-13-97"> 97</a></span>
<span class="normal"><a href="#__codelineno-13-98"> 98</a></span>
<span class="normal"><a href="#__codelineno-13-99"> 99</a></span>
<span class="normal"><a href="#__codelineno-13-100">100</a></span>
<span class="normal"><a href="#__codelineno-13-101">101</a></span>
<span class="normal"><a href="#__codelineno-13-102">102</a></span>
<span class="normal"><a href="#__codelineno-13-103">103</a></span>
<span class="normal"><a href="#__codelineno-13-104">104</a></span>
<span class="normal"><a href="#__codelineno-13-105">105</a></span>
<span class="normal"><a href="#__codelineno-13-106">106</a></span>
<span class="normal"><a href="#__codelineno-13-107">107</a></span>
<span class="normal"><a href="#__codelineno-13-108">108</a></span>
<span class="normal"><a href="#__codelineno-13-109">109</a></span>
<span class="normal"><a href="#__codelineno-13-110">110</a></span>
<span class="normal"><a href="#__codelineno-13-111">111</a></span>
<span class="normal"><a href="#__codelineno-13-112">112</a></span>
<span class="normal"><a href="#__codelineno-13-113">113</a></span>
<span class="normal"><a href="#__codelineno-13-114">114</a></span>
<span class="normal"><a href="#__codelineno-13-115">115</a></span>
<span class="normal"><a href="#__codelineno-13-116">116</a></span>
<span class="normal"><a href="#__codelineno-13-117">117</a></span>
<span class="normal"><a href="#__codelineno-13-118">118</a></span>
<span class="normal"><a href="#__codelineno-13-119">119</a></span>
<span class="normal"><a href="#__codelineno-13-120">120</a></span>
<span class="normal"><a href="#__codelineno-13-121">121</a></span>
<span class="normal"><a href="#__codelineno-13-122">122</a></span>
<span class="normal"><a href="#__codelineno-13-123">123</a></span>
<span class="normal"><a href="#__codelineno-13-124">124</a></span>
<span class="normal"><a href="#__codelineno-13-125">125</a></span>
<span class="normal"><a href="#__codelineno-13-126">126</a></span>
<span class="normal"><a href="#__codelineno-13-127">127</a></span>
<span class="normal"><a href="#__codelineno-13-128">128</a></span>
<span class="normal"><a href="#__codelineno-13-129">129</a></span>
<span class="normal"><a href="#__codelineno-13-130">130</a></span>
<span class="normal"><a href="#__codelineno-13-131">131</a></span>
<span class="normal"><a href="#__codelineno-13-132">132</a></span>
<span class="normal"><a href="#__codelineno-13-133">133</a></span>
<span class="normal"><a href="#__codelineno-13-134">134</a></span>
<span class="normal"><a href="#__codelineno-13-135">135</a></span>
<span class="normal"><a href="#__codelineno-13-136">136</a></span>
<span class="normal"><a href="#__codelineno-13-137">137</a></span>
<span class="normal"><a href="#__codelineno-13-138">138</a></span>
<span class="normal"><a href="#__codelineno-13-139">139</a></span>
<span class="normal"><a href="#__codelineno-13-140">140</a></span>
<span class="normal"><a href="#__codelineno-13-141">141</a></span>
<span class="normal"><a href="#__codelineno-13-142">142</a></span>
<span class="normal"><a href="#__codelineno-13-143">143</a></span>
<span class="normal"><a href="#__codelineno-13-144">144</a></span>
<span class="normal"><a href="#__codelineno-13-145">145</a></span>
<span class="normal"><a href="#__codelineno-13-146">146</a></span>
<span class="normal"><a href="#__codelineno-13-147">147</a></span>
<span class="normal"><a href="#__codelineno-13-148">148</a></span>
<span class="normal"><a href="#__codelineno-13-149">149</a></span>
<span class="normal"><a href="#__codelineno-13-150">150</a></span>
<span class="normal"><a href="#__codelineno-13-151">151</a></span>
<span class="normal"><a href="#__codelineno-13-152">152</a></span>
<span class="normal"><a href="#__codelineno-13-153">153</a></span>
<span class="normal"><a href="#__codelineno-13-154">154</a></span>
<span class="normal"><a href="#__codelineno-13-155">155</a></span>
<span class="normal"><a href="#__codelineno-13-156">156</a></span>
<span class="normal"><a href="#__codelineno-13-157">157</a></span>
<span class="normal"><a href="#__codelineno-13-158">158</a></span>
<span class="normal"><a href="#__codelineno-13-159">159</a></span>
<span class="normal"><a href="#__codelineno-13-160">160</a></span>
<span class="normal"><a href="#__codelineno-13-161">161</a></span>
<span class="normal"><a href="#__codelineno-13-162">162</a></span>
<span class="normal"><a href="#__codelineno-13-163">163</a></span>
<span class="normal"><a href="#__codelineno-13-164">164</a></span>
<span class="normal"><a href="#__codelineno-13-165">165</a></span>
<span class="normal"><a href="#__codelineno-13-166">166</a></span>
<span class="normal"><a href="#__codelineno-13-167">167</a></span>
<span class="normal"><a href="#__codelineno-13-168">168</a></span>
<span class="normal"><a href="#__codelineno-13-169">169</a></span>
<span class="normal"><a href="#__codelineno-13-170">170</a></span>
<span class="normal"><a href="#__codelineno-13-171">171</a></span>
<span class="normal"><a href="#__codelineno-13-172">172</a></span>
<span class="normal"><a href="#__codelineno-13-173">173</a></span>
<span class="normal"><a href="#__codelineno-13-174">174</a></span>
<span class="normal"><a href="#__codelineno-13-175">175</a></span>
<span class="normal"><a href="#__codelineno-13-176">176</a></span>
<span class="normal"><a href="#__codelineno-13-177">177</a></span>
<span class="normal"><a href="#__codelineno-13-178">178</a></span>
<span class="normal"><a href="#__codelineno-13-179">179</a></span>
<span class="normal"><a href="#__codelineno-13-180">180</a></span>
<span class="normal"><a href="#__codelineno-13-181">181</a></span>
<span class="normal"><a href="#__codelineno-13-182">182</a></span>
<span class="normal"><a href="#__codelineno-13-183">183</a></span>
<span class="normal"><a href="#__codelineno-13-184">184</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-13-1" name="__codelineno-13-1"></a><span class="c1"># Copyright (c) OpenMMLab. All rights reserved.</span>
<a id="__codelineno-13-2" name="__codelineno-13-2"></a><span class="kn">import</span> <span class="nn">torch</span>
<a id="__codelineno-13-3" name="__codelineno-13-3"></a><span class="kn">from</span> <span class="nn">bitsandbytes.optim</span> <span class="kn">import</span> <span class="n">PagedAdamW32bit</span>
<a id="__codelineno-13-4" name="__codelineno-13-4"></a><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span>
<a id="__codelineno-13-5" name="__codelineno-13-5"></a><span class="kn">from</span> <span class="nn">mmengine.dataset</span> <span class="kn">import</span> <span class="n">DefaultSampler</span>
<a id="__codelineno-13-6" name="__codelineno-13-6"></a><span class="kn">from</span> <span class="nn">mmengine.hooks</span> <span class="kn">import</span> <span class="p">(</span><span class="n">CheckpointHook</span><span class="p">,</span> <span class="n">DistSamplerSeedHook</span><span class="p">,</span> <span class="n">IterTimerHook</span><span class="p">,</span>
<a id="__codelineno-13-7" name="__codelineno-13-7"></a>                            <span class="n">LoggerHook</span><span class="p">,</span> <span class="n">ParamSchedulerHook</span><span class="p">)</span>
<a id="__codelineno-13-8" name="__codelineno-13-8"></a><span class="kn">from</span> <span class="nn">mmengine.optim</span> <span class="kn">import</span> <span class="n">AmpOptimWrapper</span><span class="p">,</span> <span class="n">CosineAnnealingLR</span>
<a id="__codelineno-13-9" name="__codelineno-13-9"></a><span class="kn">from</span> <span class="nn">peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span>
<a id="__codelineno-13-10" name="__codelineno-13-10"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span>
<a id="__codelineno-13-11" name="__codelineno-13-11"></a>                          <span class="n">BitsAndBytesConfig</span><span class="p">)</span>
<a id="__codelineno-13-12" name="__codelineno-13-12"></a>
<a id="__codelineno-13-13" name="__codelineno-13-13"></a><span class="kn">from</span> <span class="nn">xtuner.dataset</span> <span class="kn">import</span> <span class="n">process_hf_dataset</span>
<a id="__codelineno-13-14" name="__codelineno-13-14"></a><span class="kn">from</span> <span class="nn">xtuner.dataset.collate_fns</span> <span class="kn">import</span> <span class="n">default_collate_fn</span>
<a id="__codelineno-13-15" name="__codelineno-13-15"></a><span class="kn">from</span> <span class="nn">xtuner.dataset.map_fns</span> <span class="kn">import</span> <span class="n">oasst1_map_fn</span><span class="p">,</span> <span class="n">template_map_fn_factory</span>
<a id="__codelineno-13-16" name="__codelineno-13-16"></a><span class="kn">from</span> <span class="nn">xtuner.engine</span> <span class="kn">import</span> <span class="n">DatasetInfoHook</span><span class="p">,</span> <span class="n">EvaluateChatHook</span>
<a id="__codelineno-13-17" name="__codelineno-13-17"></a><span class="kn">from</span> <span class="nn">xtuner.model</span> <span class="kn">import</span> <span class="n">SupervisedFinetune</span>
<a id="__codelineno-13-18" name="__codelineno-13-18"></a><span class="kn">from</span> <span class="nn">xtuner.utils</span> <span class="kn">import</span> <span class="n">PROMPT_TEMPLATE</span>
<a id="__codelineno-13-19" name="__codelineno-13-19"></a>
<a id="__codelineno-13-20" name="__codelineno-13-20"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-21" name="__codelineno-13-21"></a><span class="c1">#                          PART 1  Settings                           #</span>
<a id="__codelineno-13-22" name="__codelineno-13-22"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-23" name="__codelineno-13-23"></a><span class="c1"># Model</span>
<a id="__codelineno-13-24" name="__codelineno-13-24"></a><span class="c1"># pretrained_model_name_or_path = &#39;internlm/internlm-chat-7b&#39;</span>
<a id="__codelineno-13-25" name="__codelineno-13-25"></a><span class="n">pretrained_model_name_or_path</span> <span class="o">=</span> <span class="s1">&#39;./internlm-chat-7b&#39;</span>
<a id="__codelineno-13-26" name="__codelineno-13-26"></a>
<a id="__codelineno-13-27" name="__codelineno-13-27"></a><span class="c1"># Data</span>
<a id="__codelineno-13-28" name="__codelineno-13-28"></a><span class="c1"># data_path = &#39;timdettmers/openassistant-guanaco&#39;</span>
<a id="__codelineno-13-29" name="__codelineno-13-29"></a><span class="n">data_path</span> <span class="o">=</span> <span class="s1">&#39;./openassistant-guanaco&#39;</span>
<a id="__codelineno-13-30" name="__codelineno-13-30"></a><span class="n">prompt_template</span> <span class="o">=</span> <span class="n">PROMPT_TEMPLATE</span><span class="o">.</span><span class="n">internlm_chat</span>
<a id="__codelineno-13-31" name="__codelineno-13-31"></a><span class="n">max_length</span> <span class="o">=</span> <span class="mi">2048</span>
<a id="__codelineno-13-32" name="__codelineno-13-32"></a><span class="n">pack_to_max_length</span> <span class="o">=</span> <span class="kc">True</span>
<a id="__codelineno-13-33" name="__codelineno-13-33"></a>
<a id="__codelineno-13-34" name="__codelineno-13-34"></a><span class="c1"># Scheduler &amp; Optimizer</span>
<a id="__codelineno-13-35" name="__codelineno-13-35"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># per_device</span>
<a id="__codelineno-13-36" name="__codelineno-13-36"></a><span class="n">accumulative_counts</span> <span class="o">=</span> <span class="mi">16</span>
<a id="__codelineno-13-37" name="__codelineno-13-37"></a><span class="n">dataloader_num_workers</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-13-38" name="__codelineno-13-38"></a><span class="n">max_epochs</span> <span class="o">=</span> <span class="mi">3</span>
<a id="__codelineno-13-39" name="__codelineno-13-39"></a><span class="n">optim_type</span> <span class="o">=</span> <span class="n">PagedAdamW32bit</span>
<a id="__codelineno-13-40" name="__codelineno-13-40"></a><span class="n">lr</span> <span class="o">=</span> <span class="mf">2e-4</span>
<a id="__codelineno-13-41" name="__codelineno-13-41"></a><span class="n">betas</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">)</span>
<a id="__codelineno-13-42" name="__codelineno-13-42"></a><span class="n">weight_decay</span> <span class="o">=</span> <span class="mi">0</span>
<a id="__codelineno-13-43" name="__codelineno-13-43"></a><span class="n">max_norm</span> <span class="o">=</span> <span class="mi">1</span>  <span class="c1"># grad clip</span>
<a id="__codelineno-13-44" name="__codelineno-13-44"></a>
<a id="__codelineno-13-45" name="__codelineno-13-45"></a><span class="c1"># Evaluate the generation performance during the training</span>
<a id="__codelineno-13-46" name="__codelineno-13-46"></a><span class="n">evaluation_freq</span> <span class="o">=</span> <span class="mi">500</span>
<a id="__codelineno-13-47" name="__codelineno-13-47"></a><span class="n">SYSTEM</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span>
<a id="__codelineno-13-48" name="__codelineno-13-48"></a><span class="n">evaluation_inputs</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-13-49" name="__codelineno-13-49"></a>    <span class="s1">&#39;请给我介绍五个上海的景点&#39;</span><span class="p">,</span> <span class="s1">&#39;Please tell me five scenic spots in Shanghai&#39;</span>
<a id="__codelineno-13-50" name="__codelineno-13-50"></a><span class="p">]</span>
<a id="__codelineno-13-51" name="__codelineno-13-51"></a>
<a id="__codelineno-13-52" name="__codelineno-13-52"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-53" name="__codelineno-13-53"></a><span class="c1">#                      PART 2  Model &amp; Tokenizer                      #</span>
<a id="__codelineno-13-54" name="__codelineno-13-54"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-55" name="__codelineno-13-55"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-56" name="__codelineno-13-56"></a>    <span class="nb">type</span><span class="o">=</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span>
<a id="__codelineno-13-57" name="__codelineno-13-57"></a>    <span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span>
<a id="__codelineno-13-58" name="__codelineno-13-58"></a>    <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-59" name="__codelineno-13-59"></a>    <span class="n">padding_side</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span>
<a id="__codelineno-13-60" name="__codelineno-13-60"></a>
<a id="__codelineno-13-61" name="__codelineno-13-61"></a><span class="n">model</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-62" name="__codelineno-13-62"></a>    <span class="nb">type</span><span class="o">=</span><span class="n">SupervisedFinetune</span><span class="p">,</span>
<a id="__codelineno-13-63" name="__codelineno-13-63"></a>    <span class="n">llm</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-64" name="__codelineno-13-64"></a>        <span class="nb">type</span><span class="o">=</span><span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">,</span>
<a id="__codelineno-13-65" name="__codelineno-13-65"></a>        <span class="n">pretrained_model_name_or_path</span><span class="o">=</span><span class="n">pretrained_model_name_or_path</span><span class="p">,</span>
<a id="__codelineno-13-66" name="__codelineno-13-66"></a>        <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-67" name="__codelineno-13-67"></a>        <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
<a id="__codelineno-13-68" name="__codelineno-13-68"></a>        <span class="n">quantization_config</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-69" name="__codelineno-13-69"></a>            <span class="nb">type</span><span class="o">=</span><span class="n">BitsAndBytesConfig</span><span class="p">,</span>
<a id="__codelineno-13-70" name="__codelineno-13-70"></a>            <span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-71" name="__codelineno-13-71"></a>            <span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-13-72" name="__codelineno-13-72"></a>            <span class="n">llm_int8_threshold</span><span class="o">=</span><span class="mf">6.0</span><span class="p">,</span>
<a id="__codelineno-13-73" name="__codelineno-13-73"></a>            <span class="n">llm_int8_has_fp16_weight</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-13-74" name="__codelineno-13-74"></a>            <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
<a id="__codelineno-13-75" name="__codelineno-13-75"></a>            <span class="n">bnb_4bit_use_double_quant</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-76" name="__codelineno-13-76"></a>            <span class="n">bnb_4bit_quant_type</span><span class="o">=</span><span class="s1">&#39;nf4&#39;</span><span class="p">)),</span>
<a id="__codelineno-13-77" name="__codelineno-13-77"></a>    <span class="n">lora</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-78" name="__codelineno-13-78"></a>        <span class="nb">type</span><span class="o">=</span><span class="n">LoraConfig</span><span class="p">,</span>
<a id="__codelineno-13-79" name="__codelineno-13-79"></a>        <span class="n">r</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
<a id="__codelineno-13-80" name="__codelineno-13-80"></a>        <span class="n">lora_alpha</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
<a id="__codelineno-13-81" name="__codelineno-13-81"></a>        <span class="n">lora_dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
<a id="__codelineno-13-82" name="__codelineno-13-82"></a>        <span class="n">bias</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span>
<a id="__codelineno-13-83" name="__codelineno-13-83"></a>        <span class="n">task_type</span><span class="o">=</span><span class="s1">&#39;CAUSAL_LM&#39;</span><span class="p">))</span>
<a id="__codelineno-13-84" name="__codelineno-13-84"></a>
<a id="__codelineno-13-85" name="__codelineno-13-85"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-86" name="__codelineno-13-86"></a><span class="c1">#                      PART 3  Dataset &amp; Dataloader                   #</span>
<a id="__codelineno-13-87" name="__codelineno-13-87"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-88" name="__codelineno-13-88"></a><span class="n">train_dataset</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-89" name="__codelineno-13-89"></a>    <span class="nb">type</span><span class="o">=</span><span class="n">process_hf_dataset</span><span class="p">,</span>
<a id="__codelineno-13-90" name="__codelineno-13-90"></a>    <span class="n">dataset</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">load_dataset</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="n">data_path</span><span class="p">),</span>
<a id="__codelineno-13-91" name="__codelineno-13-91"></a>    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<a id="__codelineno-13-92" name="__codelineno-13-92"></a>    <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
<a id="__codelineno-13-93" name="__codelineno-13-93"></a>    <span class="n">dataset_map_fn</span><span class="o">=</span><span class="n">oasst1_map_fn</span><span class="p">,</span>
<a id="__codelineno-13-94" name="__codelineno-13-94"></a>    <span class="n">template_map_fn</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-95" name="__codelineno-13-95"></a>        <span class="nb">type</span><span class="o">=</span><span class="n">template_map_fn_factory</span><span class="p">,</span> <span class="n">template</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">),</span>
<a id="__codelineno-13-96" name="__codelineno-13-96"></a>    <span class="n">remove_unused_columns</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-97" name="__codelineno-13-97"></a>    <span class="n">shuffle_before_pack</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-98" name="__codelineno-13-98"></a>    <span class="n">pack_to_max_length</span><span class="o">=</span><span class="n">pack_to_max_length</span><span class="p">)</span>
<a id="__codelineno-13-99" name="__codelineno-13-99"></a>
<a id="__codelineno-13-100" name="__codelineno-13-100"></a><span class="n">train_dataloader</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-101" name="__codelineno-13-101"></a>    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
<a id="__codelineno-13-102" name="__codelineno-13-102"></a>    <span class="n">num_workers</span><span class="o">=</span><span class="n">dataloader_num_workers</span><span class="p">,</span>
<a id="__codelineno-13-103" name="__codelineno-13-103"></a>    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
<a id="__codelineno-13-104" name="__codelineno-13-104"></a>    <span class="n">sampler</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">DefaultSampler</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
<a id="__codelineno-13-105" name="__codelineno-13-105"></a>    <span class="n">collate_fn</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">default_collate_fn</span><span class="p">))</span>
<a id="__codelineno-13-106" name="__codelineno-13-106"></a>
<a id="__codelineno-13-107" name="__codelineno-13-107"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-108" name="__codelineno-13-108"></a><span class="c1">#                    PART 4  Scheduler &amp; Optimizer                    #</span>
<a id="__codelineno-13-109" name="__codelineno-13-109"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-110" name="__codelineno-13-110"></a><span class="c1"># optimizer</span>
<a id="__codelineno-13-111" name="__codelineno-13-111"></a><span class="n">optim_wrapper</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-112" name="__codelineno-13-112"></a>    <span class="nb">type</span><span class="o">=</span><span class="n">AmpOptimWrapper</span><span class="p">,</span>
<a id="__codelineno-13-113" name="__codelineno-13-113"></a>    <span class="n">optimizer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-114" name="__codelineno-13-114"></a>        <span class="nb">type</span><span class="o">=</span><span class="n">optim_type</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="n">betas</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">),</span>
<a id="__codelineno-13-115" name="__codelineno-13-115"></a>    <span class="n">clip_grad</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">max_norm</span><span class="o">=</span><span class="n">max_norm</span><span class="p">,</span> <span class="n">error_if_nonfinite</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<a id="__codelineno-13-116" name="__codelineno-13-116"></a>    <span class="n">accumulative_counts</span><span class="o">=</span><span class="n">accumulative_counts</span><span class="p">,</span>
<a id="__codelineno-13-117" name="__codelineno-13-117"></a>    <span class="n">loss_scale</span><span class="o">=</span><span class="s1">&#39;dynamic&#39;</span><span class="p">,</span>
<a id="__codelineno-13-118" name="__codelineno-13-118"></a>    <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float16&#39;</span><span class="p">)</span>
<a id="__codelineno-13-119" name="__codelineno-13-119"></a>
<a id="__codelineno-13-120" name="__codelineno-13-120"></a><span class="c1"># learning policy</span>
<a id="__codelineno-13-121" name="__codelineno-13-121"></a><span class="c1"># More information: https://github.com/open-mmlab/mmengine/blob/main/docs/en/tutorials/param_scheduler.md  # noqa: E501</span>
<a id="__codelineno-13-122" name="__codelineno-13-122"></a><span class="n">param_scheduler</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-123" name="__codelineno-13-123"></a>    <span class="nb">type</span><span class="o">=</span><span class="n">CosineAnnealingLR</span><span class="p">,</span>
<a id="__codelineno-13-124" name="__codelineno-13-124"></a>    <span class="n">eta_min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
<a id="__codelineno-13-125" name="__codelineno-13-125"></a>    <span class="n">by_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<a id="__codelineno-13-126" name="__codelineno-13-126"></a>    <span class="n">T_max</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
<a id="__codelineno-13-127" name="__codelineno-13-127"></a>    <span class="n">convert_to_iter_based</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-13-128" name="__codelineno-13-128"></a>
<a id="__codelineno-13-129" name="__codelineno-13-129"></a><span class="c1"># train, val, test setting</span>
<a id="__codelineno-13-130" name="__codelineno-13-130"></a><span class="n">train_cfg</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">by_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span> <span class="n">val_interval</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<a id="__codelineno-13-131" name="__codelineno-13-131"></a>
<a id="__codelineno-13-132" name="__codelineno-13-132"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-133" name="__codelineno-13-133"></a><span class="c1">#                           PART 5  Runtime                           #</span>
<a id="__codelineno-13-134" name="__codelineno-13-134"></a><span class="c1">#######################################################################</span>
<a id="__codelineno-13-135" name="__codelineno-13-135"></a><span class="c1"># Log the dialogue periodically during the training process, optional</span>
<a id="__codelineno-13-136" name="__codelineno-13-136"></a><span class="n">custom_hooks</span> <span class="o">=</span> <span class="p">[</span>
<a id="__codelineno-13-137" name="__codelineno-13-137"></a>    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">DatasetInfoHook</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">),</span>
<a id="__codelineno-13-138" name="__codelineno-13-138"></a>    <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-139" name="__codelineno-13-139"></a>        <span class="nb">type</span><span class="o">=</span><span class="n">EvaluateChatHook</span><span class="p">,</span>
<a id="__codelineno-13-140" name="__codelineno-13-140"></a>        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
<a id="__codelineno-13-141" name="__codelineno-13-141"></a>        <span class="n">every_n_iters</span><span class="o">=</span><span class="n">evaluation_freq</span><span class="p">,</span>
<a id="__codelineno-13-142" name="__codelineno-13-142"></a>        <span class="n">evaluation_inputs</span><span class="o">=</span><span class="n">evaluation_inputs</span><span class="p">,</span>
<a id="__codelineno-13-143" name="__codelineno-13-143"></a>        <span class="n">system</span><span class="o">=</span><span class="n">SYSTEM</span><span class="p">,</span>
<a id="__codelineno-13-144" name="__codelineno-13-144"></a>        <span class="n">prompt_template</span><span class="o">=</span><span class="n">prompt_template</span><span class="p">)</span>
<a id="__codelineno-13-145" name="__codelineno-13-145"></a><span class="p">]</span>
<a id="__codelineno-13-146" name="__codelineno-13-146"></a>
<a id="__codelineno-13-147" name="__codelineno-13-147"></a><span class="c1"># configure default hooks</span>
<a id="__codelineno-13-148" name="__codelineno-13-148"></a><span class="n">default_hooks</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-149" name="__codelineno-13-149"></a>    <span class="c1"># record the time of every iteration.</span>
<a id="__codelineno-13-150" name="__codelineno-13-150"></a>    <span class="n">timer</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">IterTimerHook</span><span class="p">),</span>
<a id="__codelineno-13-151" name="__codelineno-13-151"></a>    <span class="c1"># print log every 100 iterations.</span>
<a id="__codelineno-13-152" name="__codelineno-13-152"></a>    <span class="n">logger</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">LoggerHook</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">10</span><span class="p">),</span>
<a id="__codelineno-13-153" name="__codelineno-13-153"></a>    <span class="c1"># enable the parameter scheduler.</span>
<a id="__codelineno-13-154" name="__codelineno-13-154"></a>    <span class="n">param_scheduler</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">ParamSchedulerHook</span><span class="p">),</span>
<a id="__codelineno-13-155" name="__codelineno-13-155"></a>    <span class="c1"># save checkpoint per epoch.</span>
<a id="__codelineno-13-156" name="__codelineno-13-156"></a>    <span class="n">checkpoint</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">CheckpointHook</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
<a id="__codelineno-13-157" name="__codelineno-13-157"></a>    <span class="c1"># set sampler seed in distributed evrionment.</span>
<a id="__codelineno-13-158" name="__codelineno-13-158"></a>    <span class="n">sampler_seed</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="n">DistSamplerSeedHook</span><span class="p">),</span>
<a id="__codelineno-13-159" name="__codelineno-13-159"></a><span class="p">)</span>
<a id="__codelineno-13-160" name="__codelineno-13-160"></a>
<a id="__codelineno-13-161" name="__codelineno-13-161"></a><span class="c1"># configure environment</span>
<a id="__codelineno-13-162" name="__codelineno-13-162"></a><span class="n">env_cfg</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
<a id="__codelineno-13-163" name="__codelineno-13-163"></a>    <span class="c1"># whether to enable cudnn benchmark</span>
<a id="__codelineno-13-164" name="__codelineno-13-164"></a>    <span class="n">cudnn_benchmark</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<a id="__codelineno-13-165" name="__codelineno-13-165"></a>    <span class="c1"># set multi process parameters</span>
<a id="__codelineno-13-166" name="__codelineno-13-166"></a>    <span class="n">mp_cfg</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">mp_start_method</span><span class="o">=</span><span class="s1">&#39;fork&#39;</span><span class="p">,</span> <span class="n">opencv_num_threads</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
<a id="__codelineno-13-167" name="__codelineno-13-167"></a>    <span class="c1"># set distributed parameters</span>
<a id="__codelineno-13-168" name="__codelineno-13-168"></a>    <span class="n">dist_cfg</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">),</span>
<a id="__codelineno-13-169" name="__codelineno-13-169"></a><span class="p">)</span>
<a id="__codelineno-13-170" name="__codelineno-13-170"></a>
<a id="__codelineno-13-171" name="__codelineno-13-171"></a><span class="c1"># set visualizer</span>
<a id="__codelineno-13-172" name="__codelineno-13-172"></a><span class="n">visualizer</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-13-173" name="__codelineno-13-173"></a>
<a id="__codelineno-13-174" name="__codelineno-13-174"></a><span class="c1"># set log level</span>
<a id="__codelineno-13-175" name="__codelineno-13-175"></a><span class="n">log_level</span> <span class="o">=</span> <span class="s1">&#39;INFO&#39;</span>
<a id="__codelineno-13-176" name="__codelineno-13-176"></a>
<a id="__codelineno-13-177" name="__codelineno-13-177"></a><span class="c1"># load from which checkpoint</span>
<a id="__codelineno-13-178" name="__codelineno-13-178"></a><span class="n">load_from</span> <span class="o">=</span> <span class="kc">None</span>
<a id="__codelineno-13-179" name="__codelineno-13-179"></a>
<a id="__codelineno-13-180" name="__codelineno-13-180"></a><span class="c1"># whether to resume training from the loaded checkpoint</span>
<a id="__codelineno-13-181" name="__codelineno-13-181"></a><span class="n">resume</span> <span class="o">=</span> <span class="kc">False</span>
<a id="__codelineno-13-182" name="__codelineno-13-182"></a>
<a id="__codelineno-13-183" name="__codelineno-13-183"></a><span class="c1"># Defaults to use random seed and disable `deterministic`</span>
<a id="__codelineno-13-184" name="__codelineno-13-184"></a><span class="n">randomness</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
</details>

<h5 id="2225">2.2.2.5 开始微调</h5>
<ul>
<li>训练</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="c1"># 单卡</span>
<a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="c1">## 用刚才改好的config文件训练</span>
<a id="__codelineno-14-3" name="__codelineno-14-3" href="#__codelineno-14-3"></a>xtuner<span class="w"> </span>train<span class="w"> </span>./internlm_chat_7b_qlora_oasst1_e3_copy.py<span class="w"> </span>--deepspeed<span class="w"> </span>deepspeed_zero2
</code></pre></div>
<p><img alt="alt text" src="../image-107.png" /></p>
<p><img alt="alt text" src="../image-108.png" /></p>
<h5 id="2226-pthlora">2.2.2.6 转换PTH模型为LoRA模型</h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a>mkdir<span class="w"> </span>hf
<a id="__codelineno-15-2" name="__codelineno-15-2" href="#__codelineno-15-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MKL_SERVICE_FORCE_INTEL</span><span class="o">=</span><span class="m">1</span>
<a id="__codelineno-15-3" name="__codelineno-15-3" href="#__codelineno-15-3"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MKL_THREADING_LAYER</span><span class="o">=</span>GNU
<a id="__codelineno-15-4" name="__codelineno-15-4" href="#__codelineno-15-4"></a>xtuner<span class="w"> </span>convert<span class="w"> </span>pth_to_hf<span class="w"> </span>./internlm_chat_7b_qlora_oasst1_e3_copy.py<span class="w"> </span>./work_dirs/internlm_chat_7b_qlora_oasst1_e3_copy/epoch_1.pth<span class="w"> </span>./hf
</code></pre></div>
<p><img alt="alt text" src="../image-109.png" /></p>
<h4 id="223">2.2.3 部署&amp;测试</h4>
<h5 id="2231-hfadapter">2.2.3.1 合并hf的adapter到大模型</h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a>xtuner<span class="w"> </span>convert<span class="w"> </span>merge<span class="w"> </span>./internlm-chat-7b<span class="w"> </span>./hf<span class="w"> </span>./merged<span class="w"> </span>--max-shard-size<span class="w"> </span>2GB
</code></pre></div>
<p><img alt="alt text" src="../image-110.png" /></p>
<h5 id="2232">2.2.3.2 与合并后的模型对话</h5>
<div class="highlight"><pre><span></span><code><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a>xtuner<span class="w"> </span>chat<span class="w"> </span>./merged<span class="w"> </span>--prompt-template<span class="w"> </span>internlm_chat
</code></pre></div>
<h5 id="2233-cli_demopy">2.2.3.3 运行测试cli_demo.py</h5>
<p>修改模型为合并后的模型</p>
<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-18-1"> 1</a></span>
<span class="normal"><a href="#__codelineno-18-2"> 2</a></span>
<span class="normal"><a href="#__codelineno-18-3"> 3</a></span>
<span class="normal"><a href="#__codelineno-18-4"> 4</a></span>
<span class="normal"><a href="#__codelineno-18-5"> 5</a></span>
<span class="normal"><a href="#__codelineno-18-6"> 6</a></span>
<span class="normal"><a href="#__codelineno-18-7"> 7</a></span>
<span class="normal"><a href="#__codelineno-18-8"> 8</a></span>
<span class="normal"><a href="#__codelineno-18-9"> 9</a></span>
<span class="normal"><a href="#__codelineno-18-10">10</a></span>
<span class="normal"><a href="#__codelineno-18-11">11</a></span>
<span class="normal"><a href="#__codelineno-18-12">12</a></span>
<span class="normal"><a href="#__codelineno-18-13">13</a></span>
<span class="normal"><a href="#__codelineno-18-14">14</a></span>
<span class="normal"><a href="#__codelineno-18-15">15</a></span>
<span class="normal"><a href="#__codelineno-18-16">16</a></span>
<span class="normal"><a href="#__codelineno-18-17">17</a></span>
<span class="normal"><a href="#__codelineno-18-18">18</a></span>
<span class="normal"><a href="#__codelineno-18-19">19</a></span>
<span class="normal"><a href="#__codelineno-18-20">20</a></span>
<span class="normal"><a href="#__codelineno-18-21">21</a></span>
<span class="normal"><a href="#__codelineno-18-22">22</a></span>
<span class="normal"><a href="#__codelineno-18-23">23</a></span>
<span class="normal"><a href="#__codelineno-18-24">24</a></span>
<span class="normal"><a href="#__codelineno-18-25">25</a></span>
<span class="normal"><a href="#__codelineno-18-26">26</a></span>
<span class="normal"><a href="#__codelineno-18-27">27</a></span>
<span class="normal"><a href="#__codelineno-18-28">28</a></span></pre></div></td><td class="code"><div><pre><span></span><code><a id="__codelineno-18-1" name="__codelineno-18-1"></a><span class="kn">import</span> <span class="nn">torch</span>
<a id="__codelineno-18-2" name="__codelineno-18-2"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">AutoModelForCausalLM</span>
<a id="__codelineno-18-3" name="__codelineno-18-3"></a>
<a id="__codelineno-18-4" name="__codelineno-18-4"></a>
<a id="__codelineno-18-5" name="__codelineno-18-5"></a><span class="c1"># model_name_or_path = &quot;/root/model/Shanghai_AI_Laboratory/internlm-chat-7b&quot;</span>
<a id="__codelineno-18-6" name="__codelineno-18-6"></a><span class="n">model_name_or_path</span> <span class="o">=</span> <span class="s2">&quot;/root/ft-oasst1/merged&quot;</span>
<a id="__codelineno-18-7" name="__codelineno-18-7"></a>
<a id="__codelineno-18-8" name="__codelineno-18-8"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<a id="__codelineno-18-9" name="__codelineno-18-9"></a><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name_or_path</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<a id="__codelineno-18-10" name="__codelineno-18-10"></a><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<a id="__codelineno-18-11" name="__codelineno-18-11"></a>
<a id="__codelineno-18-12" name="__codelineno-18-12"></a><span class="n">system_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;You are an AI assistant whose name is InternLM (书生·浦语).</span>
<a id="__codelineno-18-13" name="__codelineno-18-13"></a><span class="s2">- InternLM (书生·浦语) is a conversational language model that is developed by Shanghai AI Laboratory (上海人工智能实验室). It is designed to be helpful, honest, and harmless.</span>
<a id="__codelineno-18-14" name="__codelineno-18-14"></a><span class="s2">- InternLM (书生·浦语) can understand and communicate fluently in the language chosen by the user such as English and 中文.</span>
<a id="__codelineno-18-15" name="__codelineno-18-15"></a><span class="s2">&quot;&quot;&quot;</span>
<a id="__codelineno-18-16" name="__codelineno-18-16"></a>
<a id="__codelineno-18-17" name="__codelineno-18-17"></a><span class="n">messages</span> <span class="o">=</span> <span class="p">[(</span><span class="n">system_prompt</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)]</span>
<a id="__codelineno-18-18" name="__codelineno-18-18"></a>
<a id="__codelineno-18-19" name="__codelineno-18-19"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=============Welcome to InternLM chatbot, type &#39;exit&#39; to exit.=============&quot;</span><span class="p">)</span>
<a id="__codelineno-18-20" name="__codelineno-18-20"></a>
<a id="__codelineno-18-21" name="__codelineno-18-21"></a><span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<a id="__codelineno-18-22" name="__codelineno-18-22"></a>    <span class="n">input_text</span> <span class="o">=</span> <span class="nb">input</span><span class="p">(</span><span class="s2">&quot;User  &gt;&gt;&gt; &quot;</span><span class="p">)</span>
<a id="__codelineno-18-23" name="__codelineno-18-23"></a>    <span class="n">input_text</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
<a id="__codelineno-18-24" name="__codelineno-18-24"></a>    <span class="k">if</span> <span class="n">input_text</span> <span class="o">==</span> <span class="s2">&quot;exit&quot;</span><span class="p">:</span>
<a id="__codelineno-18-25" name="__codelineno-18-25"></a>        <span class="k">break</span>
<a id="__codelineno-18-26" name="__codelineno-18-26"></a>    <span class="n">response</span><span class="p">,</span> <span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">chat</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">input_text</span><span class="p">,</span> <span class="n">history</span><span class="o">=</span><span class="n">messages</span><span class="p">)</span>
<a id="__codelineno-18-27" name="__codelineno-18-27"></a>    <span class="n">messages</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">input_text</span><span class="p">,</span> <span class="n">response</span><span class="p">))</span>
<a id="__codelineno-18-28" name="__codelineno-18-28"></a>    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;robot &gt;&gt;&gt; </span><span class="si">{</span><span class="n">response</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
<p>运行示例脚本
<div class="highlight"><pre><span></span><code><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a>python<span class="w"> </span>Tutorial/xtuner/cli_demo.py
</code></pre></div></p>
<p><img alt="alt text" src="../image-111.png" /></p>
<h4 id="224-openxlab">2.2.4 模型&amp;应用部署到OpenXLab</h4>
<p><a href="https://aicarrier.feishu.cn/docx/MQH6dygcKolG37x0ekcc4oZhnCe">Streamlit部署参考文档</a></p>
<p><a href="https://openxlab.org.cn/docs/apps/Gradio%E5%BA%94%E7%94%A8.html#gradio-%E5%BA%94%E7%94%A8">gradio部署参考文档</a></p>
<h4 id="225">2.2.5 多模态微调</h4>
<p><a href="https://github.com/InternLM/Tutorial/blob/camp2/xtuner/llava/xtuner_llava.md">文档地址</a></p>
<h5 id="2251">2.2.5.1 环境设置</h5>
<ul>
<li>创建开发机</li>
</ul>
<p>填写 开发机名称 后，点击 选择镜像 使用 Cuda11.7-conda 镜像，然后在资源配置中，使用 50% A100 * 1 的选项，然后立即创建开发机器。
<img alt="alt text" src="../image-208.png" /></p>
<ul>
<li>Xtuner安装</li>
<li>conda环境安装</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="w">  </span><span class="nb">cd</span><span class="w"> </span>~<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>studio-conda<span class="w"> </span>xtuner0.1.17
<a id="__codelineno-20-2" name="__codelineno-20-2" href="#__codelineno-20-2"></a><span class="w">  </span><span class="c1"># 如果你是在其他平台：</span>
<a id="__codelineno-20-3" name="__codelineno-20-3" href="#__codelineno-20-3"></a><span class="w">  </span><span class="c1"># conda create --name xtuner0.1.17 python=3.10 -y</span>
</code></pre></div>
<p><img alt="alt text" src="../image-209.png" /></p>
<ul>
<li>激活环境</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="c1"># 激活环境</span>
<a id="__codelineno-21-2" name="__codelineno-21-2" href="#__codelineno-21-2"></a>conda<span class="w"> </span>activate<span class="w"> </span>xtuner0.1.17
</code></pre></div>
<ul>
<li>获取源码&amp;安装
<div class="highlight"><pre><span></span><code><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="c1"># 进入家目录 （~的意思是 “当前用户的home路径”）</span>
<a id="__codelineno-22-2" name="__codelineno-22-2" href="#__codelineno-22-2"></a><span class="nb">cd</span><span class="w"> </span>~
<a id="__codelineno-22-3" name="__codelineno-22-3" href="#__codelineno-22-3"></a><span class="c1"># 创建版本文件夹并进入</span>
<a id="__codelineno-22-4" name="__codelineno-22-4" href="#__codelineno-22-4"></a>mkdir<span class="w"> </span>-p<span class="w"> </span>/root/xtuner0117<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>/root/xtuner0117
<a id="__codelineno-22-5" name="__codelineno-22-5" href="#__codelineno-22-5"></a>
<a id="__codelineno-22-6" name="__codelineno-22-6" href="#__codelineno-22-6"></a><span class="c1"># 拉取 0.1.17 的版本源码</span>
<a id="__codelineno-22-7" name="__codelineno-22-7" href="#__codelineno-22-7"></a>git<span class="w"> </span>clone<span class="w"> </span>-b<span class="w"> </span>v0.1.17<span class="w">  </span>https://github.com/InternLM/xtuner
<a id="__codelineno-22-8" name="__codelineno-22-8" href="#__codelineno-22-8"></a><span class="c1"># 无法访问github的用户请从 gitee 拉取:</span>
<a id="__codelineno-22-9" name="__codelineno-22-9" href="#__codelineno-22-9"></a><span class="c1"># git clone -b v0.1.15 https://gitee.com/Internlm/xtuner</span>
<a id="__codelineno-22-10" name="__codelineno-22-10" href="#__codelineno-22-10"></a>
<a id="__codelineno-22-11" name="__codelineno-22-11" href="#__codelineno-22-11"></a><span class="c1"># 进入源码目录</span>
<a id="__codelineno-22-12" name="__codelineno-22-12" href="#__codelineno-22-12"></a><span class="nb">cd</span><span class="w"> </span>/root/xtuner0117/xtuner
<a id="__codelineno-22-13" name="__codelineno-22-13" href="#__codelineno-22-13"></a>
<a id="__codelineno-22-14" name="__codelineno-22-14" href="#__codelineno-22-14"></a><span class="c1"># 从源码安装 XTuner</span>
<a id="__codelineno-22-15" name="__codelineno-22-15" href="#__codelineno-22-15"></a>pip<span class="w"> </span>install<span class="w"> </span>-e<span class="w"> </span><span class="s1">&#39;.[all]&#39;</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>~
</code></pre></div></li>
</ul>
<p><img alt="alt text" src="../image-210.png" /></p>
<p><img alt="alt text" src="../image-211.png" /></p>
<h5 id="2252">2.2.5.2 预训练</h5>
<p>提供了Pretrain阶段的产物——iter_2181.pth文件。它就是幼稚园阶段的Image Projector！大家带着iter_2181.pth文件继续进入下一阶段进行Finetune即可。</p>
<div class="highlight"><pre><span></span><code><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a>share/new_models/xtuner/iter_2181.pth
</code></pre></div>
<p><img alt="alt text" src="../image-212.png" /></p>
<h5 id="2253">2.2.5.3 微调</h5>
<ul>
<li>格式示意</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="p">[</span>
<a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="w">  </span><span class="p">{</span>
<a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a><span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;000000033471&quot;</span><span class="p">,</span>
<a id="__codelineno-24-4" name="__codelineno-24-4" href="#__codelineno-24-4"></a><span class="w">    </span><span class="nt">&quot;image&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;coco/train2017/000000033471.jpg&quot;</span><span class="p">,</span>
<a id="__codelineno-24-5" name="__codelineno-24-5" href="#__codelineno-24-5"></a><span class="w">    </span><span class="nt">&quot;conversations&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-24-6" name="__codelineno-24-6" href="#__codelineno-24-6"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-7" name="__codelineno-24-7" href="#__codelineno-24-7"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;human&quot;</span><span class="p">,</span>
<a id="__codelineno-24-8" name="__codelineno-24-8" href="#__codelineno-24-8"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;image&gt;\nWhat are the colors of the bus in the image?&quot;</span>
<a id="__codelineno-24-9" name="__codelineno-24-9" href="#__codelineno-24-9"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-10" name="__codelineno-24-10" href="#__codelineno-24-10"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-11" name="__codelineno-24-11" href="#__codelineno-24-11"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt&quot;</span><span class="p">,</span>
<a id="__codelineno-24-12" name="__codelineno-24-12" href="#__codelineno-24-12"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The bus in the image is white and red.&quot;</span>
<a id="__codelineno-24-13" name="__codelineno-24-13" href="#__codelineno-24-13"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-14" name="__codelineno-24-14" href="#__codelineno-24-14"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-15" name="__codelineno-24-15" href="#__codelineno-24-15"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;human&quot;</span><span class="p">,</span>
<a id="__codelineno-24-16" name="__codelineno-24-16" href="#__codelineno-24-16"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;What feature can be seen on the back of the bus?&quot;</span>
<a id="__codelineno-24-17" name="__codelineno-24-17" href="#__codelineno-24-17"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-18" name="__codelineno-24-18" href="#__codelineno-24-18"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-19" name="__codelineno-24-19" href="#__codelineno-24-19"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt&quot;</span><span class="p">,</span>
<a id="__codelineno-24-20" name="__codelineno-24-20" href="#__codelineno-24-20"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The back of the bus features an advertisement.&quot;</span>
<a id="__codelineno-24-21" name="__codelineno-24-21" href="#__codelineno-24-21"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-22" name="__codelineno-24-22" href="#__codelineno-24-22"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-23" name="__codelineno-24-23" href="#__codelineno-24-23"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;human&quot;</span><span class="p">,</span>
<a id="__codelineno-24-24" name="__codelineno-24-24" href="#__codelineno-24-24"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Is the bus driving down the street or pulled off to the side?&quot;</span>
<a id="__codelineno-24-25" name="__codelineno-24-25" href="#__codelineno-24-25"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-26" name="__codelineno-24-26" href="#__codelineno-24-26"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-27" name="__codelineno-24-27" href="#__codelineno-24-27"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt&quot;</span><span class="p">,</span>
<a id="__codelineno-24-28" name="__codelineno-24-28" href="#__codelineno-24-28"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The bus is driving down the street, which is crowded with people and other vehicles.&quot;</span>
<a id="__codelineno-24-29" name="__codelineno-24-29" href="#__codelineno-24-29"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-24-30" name="__codelineno-24-30" href="#__codelineno-24-30"></a><span class="w">    </span><span class="p">]</span>
<a id="__codelineno-24-31" name="__codelineno-24-31" href="#__codelineno-24-31"></a><span class="w">  </span><span class="p">},</span>
<a id="__codelineno-24-32" name="__codelineno-24-32" href="#__codelineno-24-32"></a><span class="w">  </span><span class="p">{</span>
<a id="__codelineno-24-33" name="__codelineno-24-33" href="#__codelineno-24-33"></a><span class="w">    </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;000000052846&quot;</span><span class="p">,</span>
<a id="__codelineno-24-34" name="__codelineno-24-34" href="#__codelineno-24-34"></a><span class="w">    </span><span class="nt">&quot;image&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;coco/train2017/000000052846.jpg&quot;</span><span class="p">,</span>
<a id="__codelineno-24-35" name="__codelineno-24-35" href="#__codelineno-24-35"></a><span class="w">    </span><span class="nt">&quot;conversations&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<a id="__codelineno-24-36" name="__codelineno-24-36" href="#__codelineno-24-36"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-37" name="__codelineno-24-37" href="#__codelineno-24-37"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;human&quot;</span><span class="p">,</span>
<a id="__codelineno-24-38" name="__codelineno-24-38" href="#__codelineno-24-38"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;image&gt;\nWhere is the cat positioned in the image?&quot;</span>
<a id="__codelineno-24-39" name="__codelineno-24-39" href="#__codelineno-24-39"></a><span class="w">      </span><span class="p">},</span>
<a id="__codelineno-24-40" name="__codelineno-24-40" href="#__codelineno-24-40"></a><span class="w">      </span><span class="p">{</span>
<a id="__codelineno-24-41" name="__codelineno-24-41" href="#__codelineno-24-41"></a><span class="w">        </span><span class="nt">&quot;from&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;gpt&quot;</span><span class="p">,</span>
<a id="__codelineno-24-42" name="__codelineno-24-42" href="#__codelineno-24-42"></a><span class="w">        </span><span class="nt">&quot;value&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;The cat is positioned on top of the back of the couch in the living room.&quot;</span>
<a id="__codelineno-24-43" name="__codelineno-24-43" href="#__codelineno-24-43"></a><span class="w">      </span><span class="p">}</span>
<a id="__codelineno-24-44" name="__codelineno-24-44" href="#__codelineno-24-44"></a><span class="w">    </span><span class="p">]</span>
<a id="__codelineno-24-45" name="__codelineno-24-45" href="#__codelineno-24-45"></a><span class="w">  </span><span class="p">}</span>
<a id="__codelineno-24-46" name="__codelineno-24-46" href="#__codelineno-24-46"></a><span class="w"> </span><span class="p">]</span>
<a id="__codelineno-24-47" name="__codelineno-24-47" href="#__codelineno-24-47"></a><span class="w"> </span><span class="err">```</span>
<a id="__codelineno-24-48" name="__codelineno-24-48" href="#__codelineno-24-48"></a>
<a id="__codelineno-24-49" name="__codelineno-24-49" href="#__codelineno-24-49"></a><span class="w"> </span><span class="mi">-</span><span class="w"> </span><span class="err">生成问答对数据(repea</span><span class="kc">t</span><span class="err">_da</span><span class="kc">ta</span><span class="err">.jso</span><span class="kc">n</span><span class="err">)</span>
<a id="__codelineno-24-50" name="__codelineno-24-50" href="#__codelineno-24-50"></a>
<a id="__codelineno-24-51" name="__codelineno-24-51" href="#__codelineno-24-51"></a><span class="w"> </span><span class="err">```bash</span>
<a id="__codelineno-24-52" name="__codelineno-24-52" href="#__codelineno-24-52"></a><span class="w"> </span><span class="err">cd</span><span class="w"> </span><span class="err">~</span><span class="w"> </span><span class="err">&amp;&amp;</span><span class="w"> </span><span class="err">gi</span><span class="kc">t</span><span class="w"> </span><span class="err">clo</span><span class="kc">ne</span><span class="w"> </span><span class="err">h</span><span class="kc">tt</span><span class="err">ps</span><span class="p">:</span><span class="c1">//github.com/InternLM/tutorial -b camp2 &amp;&amp; conda activate xtuner0.1.17 &amp;&amp; cd tutorial</span>
<a id="__codelineno-24-53" name="__codelineno-24-53" href="#__codelineno-24-53"></a>
<a id="__codelineno-24-54" name="__codelineno-24-54" href="#__codelineno-24-54"></a><span class="err">py</span><span class="kc">t</span><span class="err">ho</span><span class="kc">n</span><span class="w"> </span><span class="err">/roo</span><span class="kc">t</span><span class="err">/</span><span class="kc">tut</span><span class="err">orial/x</span><span class="kc">tuner</span><span class="err">/llava/llava_da</span><span class="kc">ta</span><span class="err">/repea</span><span class="kc">t</span><span class="err">.py</span><span class="w"> </span><span class="err">\</span>
<a id="__codelineno-24-55" name="__codelineno-24-55" href="#__codelineno-24-55"></a><span class="w">  </span><span class="mi">-</span><span class="err">i</span><span class="w"> </span><span class="err">/roo</span><span class="kc">t</span><span class="err">/</span><span class="kc">tut</span><span class="err">orial/x</span><span class="kc">tuner</span><span class="err">/llava/llava_da</span><span class="kc">ta</span><span class="err">/u</span><span class="kc">n</span><span class="err">ique_da</span><span class="kc">ta</span><span class="err">.jso</span><span class="kc">n</span><span class="w"> </span><span class="err">\</span>
<a id="__codelineno-24-56" name="__codelineno-24-56" href="#__codelineno-24-56"></a><span class="w">  </span><span class="mi">-</span><span class="err">o</span><span class="w"> </span><span class="err">/roo</span><span class="kc">t</span><span class="err">/</span><span class="kc">tut</span><span class="err">orial/x</span><span class="kc">tuner</span><span class="err">/llava/llava_da</span><span class="kc">ta</span><span class="err">/repea</span><span class="kc">te</span><span class="err">d_da</span><span class="kc">ta</span><span class="err">.jso</span><span class="kc">n</span><span class="w"> </span><span class="err">\</span>
<a id="__codelineno-24-57" name="__codelineno-24-57" href="#__codelineno-24-57"></a><span class="w">  </span><span class="mi">-</span><span class="kc">n</span><span class="w"> </span><span class="mi">200</span>
<a id="__codelineno-24-58" name="__codelineno-24-58" href="#__codelineno-24-58"></a><span class="w">  </span><span class="err">```</span>
<a id="__codelineno-24-59" name="__codelineno-24-59" href="#__codelineno-24-59"></a>
<a id="__codelineno-24-60" name="__codelineno-24-60" href="#__codelineno-24-60"></a><span class="err">!</span><span class="p">[</span><span class="err">al</span><span class="kc">t</span><span class="w"> </span><span class="kc">te</span><span class="err">x</span><span class="kc">t</span><span class="p">]</span><span class="err">(image</span><span class="mf">-213.</span><span class="err">p</span><span class="kc">n</span><span class="err">g)</span>
<a id="__codelineno-24-61" name="__codelineno-24-61" href="#__codelineno-24-61"></a>
<a id="__codelineno-24-62" name="__codelineno-24-62" href="#__codelineno-24-62"></a><span class="mi">-</span><span class="w"> </span><span class="err">获取配置文件</span>
<a id="__codelineno-24-63" name="__codelineno-24-63" href="#__codelineno-24-63"></a>
<a id="__codelineno-24-64" name="__codelineno-24-64" href="#__codelineno-24-64"></a><span class="err">```bash</span>
<a id="__codelineno-24-65" name="__codelineno-24-65" href="#__codelineno-24-65"></a><span class="err">cp</span><span class="w"> </span><span class="err">/roo</span><span class="kc">t</span><span class="err">/</span><span class="kc">tut</span><span class="err">orial/x</span><span class="kc">tuner</span><span class="err">/llava/llava_da</span><span class="kc">ta</span><span class="err">/i</span><span class="kc">nternl</span><span class="err">m</span><span class="mi">2</span><span class="err">_cha</span><span class="kc">t</span><span class="err">_</span><span class="mi">1</span><span class="err">_</span><span class="mi">8</span><span class="err">b_llava_</span><span class="kc">tut</span><span class="err">orial_</span><span class="kc">f</span><span class="err">ool_co</span><span class="kc">nf</span><span class="err">ig.py</span><span class="w"> </span><span class="err">/roo</span><span class="kc">t</span><span class="err">/</span><span class="kc">tut</span><span class="err">orial/x</span><span class="kc">tuner</span><span class="err">/llava/llava_i</span><span class="kc">nternl</span><span class="err">m</span><span class="mi">2</span><span class="err">_cha</span><span class="kc">t</span><span class="err">_</span><span class="mi">1</span><span class="err">_</span><span class="mi">8</span><span class="err">b_qlora_clip_vi</span><span class="kc">t</span><span class="err">_large_p</span><span class="mi">14</span><span class="err">_</span><span class="mi">336</span><span class="err">_lora_e</span><span class="mi">1</span><span class="err">_gpu</span><span class="mi">8</span><span class="err">_</span><span class="kc">f</span><span class="err">i</span><span class="kc">netune</span><span class="err">_copy.py</span>
</code></pre></div>
<p><img alt="alt text" src="../image-214.png" /></p>
<ul>
<li>开始微调</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="nb">cd</span><span class="w"> </span>/root/tutorial/xtuner/llava/
<a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>xtuner<span class="w"> </span>train<span class="w"> </span>/root/tutorial/xtuner/llava/llava_internlm2_chat_1_8b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune_copy.py<span class="w"> </span>--deepspeed<span class="w"> </span>deepspeed_zero2
</code></pre></div>
<p><img alt="alt text" src="../image-215.png" /></p>
<p><img alt="alt text" src="../image-216.png" /></p>
<p><img alt="alt text" src="../image-218.png" /></p>
<h5 id="2254">2.2.5.4 微调模型对话</h5>
<ul>
<li>多卡环境设置</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MKL_SERVICE_FORCE_INTEL</span><span class="o">=</span><span class="m">1</span>
<a id="__codelineno-26-2" name="__codelineno-26-2" href="#__codelineno-26-2"></a><span class="nb">export</span><span class="w"> </span><span class="nv">MKL_THREADING_LAYER</span><span class="o">=</span>GNU
</code></pre></div>
<ul>
<li>pth转huggingface</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a>xtuner<span class="w"> </span>convert<span class="w"> </span>pth_to_hf<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-27-2" name="__codelineno-27-2" href="#__codelineno-27-2"></a><span class="w">  </span>/root/tutorial/xtuner/llava/llava_internlm2_chat_1_8b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune_copy.py<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-27-3" name="__codelineno-27-3" href="#__codelineno-27-3"></a><span class="w">  </span>/root/tutorial/xtuner/llava/work_dirs/llava_internlm2_chat_1_8b_qlora_clip_vit_large_p14_336_lora_e1_gpu8_finetune_copy/iter_1200.pth<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-27-4" name="__codelineno-27-4" href="#__codelineno-27-4"></a><span class="w">  </span>/root/tutorial/xtuner/llava/llava_data/iter_1200_hf
</code></pre></div>
<p><img alt="alt text" src="../image-219.png" /></p>
<ul>
<li>chat</li>
</ul>
<div class="highlight"><pre><span></span><code><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a>xtuner<span class="w"> </span>chat<span class="w"> </span>/root/share/new_models/Shanghai_AI_Laboratory/internlm2-chat-1_8b<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-28-2" name="__codelineno-28-2" href="#__codelineno-28-2"></a><span class="w">  </span>--visual-encoder<span class="w"> </span>/root/share/new_models/openai/clip-vit-large-patch14-336<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-28-3" name="__codelineno-28-3" href="#__codelineno-28-3"></a><span class="w">  </span>--llava<span class="w"> </span>/root/tutorial/xtuner/llava/llava_data/iter_1200_hf<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-28-4" name="__codelineno-28-4" href="#__codelineno-28-4"></a><span class="w">  </span>--prompt-template<span class="w"> </span>internlm2_chat<span class="w"> </span><span class="se">\</span>
<a id="__codelineno-28-5" name="__codelineno-28-5" href="#__codelineno-28-5"></a><span class="w">  </span>--image<span class="w"> </span>/root/tutorial/xtuner/llava/llava_data/test_img/oph.jpg
</code></pre></div>
<p><img alt="alt text" src="../image-220.png" /></p>
<h2 id="3">3. 视频总结</h2>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      &copy; 2023 <a href="https://github.com/acondess" target="_blank" rel="noopener">acondess</a>
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://acondess.github.io/InternLM_learn_2/" target="_blank" rel="noopener" title="acondess.github.io" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 2A10 10 0 0 0 2 12c0 4.42 2.87 8.17 6.84 9.5.5.08.66-.23.66-.5v-1.69c-2.77.6-3.36-1.34-3.36-1.34-.46-1.16-1.11-1.47-1.11-1.47-.91-.62.07-.6.07-.6 1 .07 1.53 1.03 1.53 1.03.87 1.52 2.34 1.07 2.91.83.09-.65.35-1.09.63-1.34-2.22-.25-4.55-1.11-4.55-4.92 0-1.11.38-2 1.03-2.71-.1-.25-.45-1.29.1-2.64 0 0 .84-.27 2.75 1.02.79-.22 1.65-.33 2.5-.33.85 0 1.71.11 2.5.33 1.91-1.29 2.75-1.02 2.75-1.02.55 1.35.2 2.39.1 2.64.65.71 1.03 1.6 1.03 2.71 0 3.82-2.34 4.66-4.57 4.91.36.31.69.92.69 1.85V21c0 .27.16.59.67.5C19.14 20.16 22 16.42 22 12A10 10 0 0 0 12 2Z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.tracking", "navigation.tabs.sticky", "navigation.top", "navigation.tabs", "navigation.expand", "navigation.sections", "toc.integrate", "toc.sections", "toc.follow", "toc.numbers", "search.suggest", "search.highlight", "content.tabs.link", "content.code.annotation", "content.code.copy", "footer"], "search": "../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../assets/javascripts/bundle.5cfa9459.min.js"></script>
      
    
  </body>
</html>